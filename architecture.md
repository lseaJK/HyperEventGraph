# 基于超关系图的事理图谱构建方法——架构文档

## 一、 任务目标

构建一个基于超关系图（HyperGraph）的事理图谱（Causal Knowledge Graph）构建方法。该方法利用`HyperGraphRAG`作为核心，并结合自定义的事件Schema，旨在从非结构化和半结构化文本（特别是金融和集成电路领域）中，高效地抽取出事件及其内在联系，并以超图的形式进行存储和查询。

## 二、 核心组件

1.  **HyperGraphRAG**: 作为核心的知识表示和检索增强生成框架。
2.  **事件Schema**: 
    - **金融领域**: 基于金融行业业务本体论 (FIBO) 进行设计。
      - **事件类型**: 
        - `公司并购 (Merger & Acquisition)`: `收购方`, `被收购方`, `交易金额`, `并购状态`, `公告日期`
        - `投融资 (Investment & Financing)`: `投资方`, `融资方`, `融资金额`, `轮次`, `相关产品`
        - `高管变动 (Executive Change)`: `公司`, `变动高管`, `职位`, `变动类型(上任/离职)`
        - `法律诉讼 (Legal Proceeding)`: `原告`, `被告`, `诉讼原因`, `涉及金额`, `判决结果`
        - `业绩报告 (Financial Report)`: `公司`, `报告期`, `营收`, `净利润`, `同比增长率`
    - **集成电路领域**: 由于缺乏统一标准，将根据行业知识（如：供应链、制造流程、市场动态等）自定义事件类型及属性。
      - **事件类型**:
        - `产能扩张 (Capacity Expansion)`: `公司`, `工厂地点`, `投资金额`, `新增产能`, `技术节点`
        - `技术突破 (Technological Breakthrough)`: `公司/研究机构`, `技术名称`, `关键指标`, `应用领域`
        - `供应链风险 (Supply Chain Risk)`: `公司`, `风险类型(断供/涨价)`, `影响环节`, `涉及物料`
        - `新产品发布 (New Product Launch)`: `公司`, `产品型号`, `性能参数`, `目标市场`
        - `行业政策 (Industry Policy)`: `发布机构`, `政策名称`, `核心内容`, `影响范围`
3.  **事件抽取与图谱构建**: 
    - **数据预处理**: 设计一个统一的模块，负责处理不同来源的语料，如纯文本、PDF、网页等，将其转化为统一的文本格式。
    - **事件抽取 (Prompt-based)**: 
      - 设计针对性的提示词（Prompt），指导大型语言模型（LLM）根据预定义的事件Schema，从预处理后的文本中识别和抽取出事件的关键属性。
      - Prompt模板需要包含清晰的指令、事件定义、属性列表以及输出格式要求（如JSON）。
      - **示例Prompt**: `你是一个金融事件分析专家。请从以下文本中，抽取出“公司并购”事件，并以JSON格式返回结果，包含'收购方', '被收购方', '交易金额', '公告日期'等字段。如果信息不存在，请用null填充。文本：“【公司A宣布以50亿美元收购公司B】......”`
    - **图谱构建 (HyperGraphRAG)**:
      - 将LLM抽取的事件JSON数据，转换为`HyperGraphRAG`接受的`unique_contexts`格式。
      - 每个事件可以被视为一个“超边（Hyperedge）”，连接所有相关的实体（节点），如`公司`、`人物`、`产品`等。
      - 调用`rag.insert(unique_contexts)`方法，将事件超边和相关实体节点批量存入知识超图。

## 三、 工作流程规划

采用测试驱动开发（TDD）的模式，分阶段进行。

1.  **阶段一：调研与设计（已完成）**
    - [x] 研究`HyperGraphRAG`的核心功能。
    - [x] 调研金融和集成电路领域的事件本体/Schema。
    - [x] 完成`architecture.md`的初步设计。

5.  **阶段一附录：外部资源调研结论**

    - **调研节点**: 001
    - **使用工具**: `Sequential Thinking`, `DuckDuckGo Search Server`, `Context7`
    - **策略**:
      1. 分析通用金融事件研究工具 (`eventstudy` 仓库)。
      2. 搜索特定领域（集成电路、银行业务）的金融事件语料库、本体或工具。
    - **结论与洞察**:
      1.  **通用工具的价值与局限**: `eventstudy` 这样的量化分析工具为“金融事件”提供了结构化的定义范式（事件标识、日期、关联实体），这对我们设计图谱的 Schema 很有启发。然而，它本身是事件分析工具，而非事件抽取工具，不提供语料收集功能。 (详见: `docs/related_research.md`)
      2.  **特定领域语料库的稀缺性**: 经过多轮搜索，未发现公开的、专门针对“集成电路”或“银行业务”的、已标注的金融事件语料库。相关的数据集主要集中在硬件设计 (`AICircuit`) 或文字识别 (`ICText`) 等非金融领域。 (详见: `docs/irrelevant_research.md`)
      3.  **策略调整**: 鉴于直接的领域语料库难以获取，项目需要调整策略。下一步的重点将是：
          - **转向通用金融事件语料库 (已尝试)**: 尝试搜索通用事件抽取数据集（如 ACE, MAVEN），但由于工具限制或资源稀缺，未能获取有效信息。**结论：寻找现成语料库的路径已走到尽头。**
          - **探索弱监督/无监督方法 (下一步重点)**: 鉴于上述结论，项目正式将重心转向探索如何利用NLP工具链（如 spaCy, Flair, OpenNRE 等）和弱监督/无监督方法，从大规模无标注新闻文本中自动发现和构建事件语料。需要研究的重点包括：命名实体识别 (NER)、关系抽取 (Relation Extraction) 和事件论元抽取 (Event Argument Extraction) 的实现方案。

    - **待调研的外部资源**:
      - [casually-fine-tuned/awesome-financial-events](https://github.com/casually-fine-tuned/awesome-financial-events)
      - [Event-Study-Tools/event-study](https://github.com/Event-Study-Tools/event-study)
      - [acorn-datasets/sentifm](https://huggingface.co/datasets/acorn-datasets/sentifm)
      - [hi-alice/FNER](https://github.com/hi-alice/FNER)
      - [midas-research/financial-event-dataset](https://github.com/midas-research/financial-event-dataset)

## 会话存档 (2024-07-29)

**核心结论**:

当前工作暂时告一段落。已将项目的中期目标和技术选型（弱监督方法、spaCy、Flair、OpenNRE等）记录在案，以便后续工作可以无缝衔接。

**下一步行动计划**:

1.  **待续**: 下次将从“技术原型开发 (弱监督)”阶段开始，重点评估和选择合适的NLP工具链，并着手实现初步的事件语料自动构建流水线。


**核心结论**:

经过对多个参考仓库的分析，我们确认了项目的核心技术路径：利用大型语言模型 (LLM) 和 Prompt Engineering 进行金融事件抽取。同时，我们认识到，在缺少大规模标注数据的情况下，直接微调模型存在挑战。因此，项目的下一个关键阶段是探索弱监督和无监督方法，以自动化地从无结构文本中构建事件语料。

**下一步行动计划**:

1.  **事件 Schema 细化**: 基于 `SentiFM` 数据集和金融领域知识，进一步完善 `architecture.md` 中定义的事件 Schema，使其更具通用性和覆盖性。
2.  **技术原型开发 (弱监督)**:
    *   **工具选型**: 重点评估 `spaCy`, `Flair`, `OpenNRE` 等NLP工具在命名实体识别 (NER) 和关系抽取任务上的表现。
    *   **实现路径**: 设计并实现一个初步的流水线，该流水线能够：
        1.  利用预训练的 NER 模型识别文本中的实体（如公司、人名、地点）。
        2.  基于预定义的规则或启发式方法，抽取实体间的潜在关系。
        3.  将抽取的“伪标签”数据用于训练一个初步的事件抽取模型。
3.  **知识图谱集成**: 将抽取的结构化事件数据，按照预定义的图谱模式，存入知识图谱（如 Neo4j），并记录相关决策于本文档。

**决策记录**: 本次会话的所有分析和规划都已记录在案，并同步更新到项目的知识图谱中，以便于未来的任务延续和决策追溯。


2.  **阶段二：原型开发**
    - [ ] **TDD-1**: 开发数据预处理模块，并编写单元测试，确保能正确处理txt, pdf等格式。
    - [ ] **TDD-2**: 开发事件抽取模块，针对每个事件类型编写测试用例，验证Prompt的有效性和LLM抽取的准确性。
    - [ ] **TDD-3**: 开发图谱构建模块，测试事件数据能否成功转换为超图结构并存入`HyperGraphRAG`。

3.  **阶段三：评估与迭代**
    - [ ] 使用标准数据集或人工标注数据，评估端到端的事件抽取和图谱构建效果。
    - [ ] 根据评估结果，迭代优化Prompt设计、事件Schema和处理流程。
    - [ ] 完善文档和代码，确保可复现性和可扩展性。

## 四、 提交规范

- 代码、测试、文档分支提交，Commit 规范：
  ```
  feat: 添加子任务 XXX 实现及单元测试
  fix: 修复子任务 XXX 异常场景
  docs: 更新 architecture.md 中 XXX 节点
  ```