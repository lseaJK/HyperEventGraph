{
  "master": {
    "tasks": [
      {
        "id": 1,
        "title": "第一阶段：环境与骨架搭建",
        "description": "根据需求文档V2.1，完成第一阶段的环境与骨架搭建。这包括更新依赖、确认设计文档、并创建所有必要的Agent和Admin模块的文件骨架。这个阶段为后续的Agent能力开发和工作流编排奠定基础。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 2,
        "title": "第二阶段：Agent能力工具化",
        "description": "根据需求文档V2.1，完成第二阶段的Agent能力工具化。核心任务是将项目中现有的事件抽取、关系分析、分类和存储逻辑，封装成独立的Python函数，并作为“工具”注册给对应的Agent（ExtractionAgent, RelationshipAnalysisAgent, TriageAgent, StorageAgent）。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          1
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 3,
        "title": "第三阶段：工作流编排与测试",
        "description": "根据需求文档V2.1，完成第三阶段的工作流编排与测试。主要工作是在一个主流程脚本中，使用AutoGen的GroupChatManager来初始化所有Agent，并定义它们之间的协作流程。同时，需要编写并运行集成测试，确保整个工作流在不同场景下都能稳定、正确地运行。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          2
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 4,
        "title": "第四阶段：后台学习系统实现",
        "description": "根据需求文档V2.1，完成第四阶段的后台学习系统实现。这包括实现SchemaLearnerAgent的核心能力（如聚类、归纳），定义一个用于后台学习的独立GroupChat，并创建一个简单的管理模块（AdminModule）来启动学习流程和处理人工审核。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          3
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "实现SchemaLearnerAgent的核心能力",
            "description": "实现SchemaLearnerAgent的聚类和归纳功能，并为这些核心功能编写单元测试以确保其正确性。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          },
          {
            "id": 2,
            "title": "定义并实现后台学习的GroupChat",
            "description": "基于AutoGen定义一个专用于后台学习的GroupChat，并进行配置，确保Agent可以在其中正确协作。编写初步的集成测试验证Chat的设置。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          },
          {
            "id": 3,
            "title": "创建AdminModule用于启动和审核",
            "description": "创建一个简单的AdminModule，提供启动后台学习流程的接口，并能接收学习结果以供人工审核。此模块的功能需要通过测试验证。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          },
          {
            "id": 4,
            "title": "集成并测试后台学习系统",
            "description": "将SchemaLearnerAgent, GroupChat, 和AdminModule集成在一起，形成完整的后台学习工作流。编写端到端测试，模拟一次完整的学习、审核流程，确保系统稳定运行。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 4
          }
        ]
      },
      {
        "id": 5,
        "title": "第五阶段：重构事件抽取和验证模块",
        "description": "重构事件抽取和验证模块，以提高准确性和可维护性。这可能包括重新设计Schema、改进抽取逻辑或增强验证步骤。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "建立统一的Pydantic Schema作为唯一真实来源",
            "description": "让 schemas.py 成为事件定义的唯一真实来源 (Single Source of Truth)。基于 event_schemas.json 的结构，在 schemas.py 中创建或完善所有事件的 Pydantic 模型。添加一个工具函数，可以从 Pydantic 模型动态生成 JSON Schema。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 2,
            "title": "定义抽取器抽象基类(BaseEventExtractor)",
            "description": "解耦服务和具体的抽取器实现。创建一个 base_extractor.py 文件，在其中定义一个抽象基类 BaseEventExtractor，并规定所有抽取器都必须实现的核心方法（如 extract）。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 3,
            "title": "使验证器适配Pydantic并集成deepseek-chat",
            "description": "简化验证流程。改造 EventExtractionValidator，使其直接使用 schemas.py 中的 Pydantic 模型进行验证，而不是读取外部 JSON 文件。在需要时集成 deepseek-chat 进行名称匹配。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 4,
            "title": "重构 EventExtractionService 以实现依赖注入",
            "description": "实现依赖注入，降低耦合。修改 EventExtractionService 的构造函数，使其不再自己创建实例，而是接收一个 BaseEventExtractor 类型的对象作为参数。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 5,
            "title": "适配 DeepSeekEventExtractor 以符合新接口",
            "description": "使现有实现符合新标准。让 DeepSeekEventExtractor 继承自新的 BaseEventExtractor，并确保其返回的数据是 schemas.py 中定义的 Pydantic 模型实例。在需要时利用 deepseek-chat 进行实体标准化。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 6,
            "title": "清理冗余文件和代码",
            "description": "移除废弃内容。在所有重构完成后，安全地删除 event_schemas.json 和旧的 extractor.py。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          },
          {
            "id": 7,
            "title": "更新单元测试以匹配新架构",
            "description": "确保新架构的稳定性。更新所有受影响的单元测试，以匹配新的类构造方式和数据返回类型。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 5
          }
        ]
      },
      {
        "id": 6,
        "title": "重构实体去重模块以集成LLM进行智能标准化",
        "description": "重构实体去重模块(EntityDeduplicator)，集成大模型能力以提高名称标准化的准确性。当前模块过于依赖固定的后缀规则，导致对'Tencent Holdings'等名称的错误处理。新的实现将采用混合策略：优先使用保守的规则进行快速处理，对于复杂情况则调用大模型进行智能判断。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "修改 EntityDeduplicator 构造函数以支持 LLM 客户端",
            "description": "更新 EntityDeduplicator 的 __init__ 方法，使其能够接收并存储一个LLM客户端实例。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          },
          {
            "id": 2,
            "title": "实现 LLM 驱动的名称标准化方法",
            "description": "创建 _normalize_name_with_llm 方法，该方法将使用few-shot prompt调用LLM来获取标准化的实体名称。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          },
          {
            "id": 3,
            "title": "在匹配函数中集成 LLM 标准化逻辑",
            "description": "在 _exact_match_score 和 _alias_match_score 中引入调用新LLM标准化方法的逻辑。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          },
          {
            "id": 4,
            "title": "更新单元测试以覆盖新逻辑",
            "description": "更新并添加单元测试，以验证新的规则和LLM标准化逻辑。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 6
          }
        ]
      },
      {
        "id": 7,
        "title": "重构工作流以支持异步、文件驱动的人机交互",
        "description": "将一次性的 `run_agent_workflow.py` 脚本重构为一个可中断、可恢复的异步工作流。该工作流将通过状态文件和审核文件与用户进行交互，以适应用户无法实时在线的场景。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "设计并实现状态管理系统",
            "description": "创建 workflow_state.json 的数据结构。实现加载和保存工作流状态的函数，包括当前阶段、输入文件路径、分流结果、已抽取的事件和关系等。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 2,
            "title": "创建主工作流控制器",
            "description": "开发新的 run_async_workflow.py 脚本。该脚本将作为工作流的唯一入口点，负责读取状态、调度不同阶段的执行，并处理用户回复。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 3,
            "title": "重构“分流”阶段为异步模块",
            "description": "将 TriageAgent 的逻辑封装成一个独立的函数。该函数执行后，会更新状态文件，并生成一个 review_request.txt，要求用户确认事件分类。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 4,
            "title": "重构“抽取”阶段为异步模块",
            "description": "将 ExtractionAgent 的逻辑封装成一个独立的函数。该函数在用户确认分流后执行，将抽取的事件写入状态文件，并生成一个新的 review_request.txt，要求用户审核或修正抽取结果。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 5,
            "title": "重构“关系分析与存储”阶段",
            "description": "将 RelationshipAnalysisAgent 和 StorageAgent 的逻辑合并为一个最终处理函数。该函数在用户确认抽取结果后执行，完成关系分析、数据存储，并最终将工作流状态标记为“完成”。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 6,
            "title": "实现用户反馈处理逻辑",
            "description": "在主控制器中，开发用于解析 review_response.txt 的功能。根据用户的回复（例如，status: CONFIRMED 或 data: [...]），更新 workflow_state.json。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          },
          {
            "id": 7,
            "title": "编写用户操作指南",
            "description": "创建一个 README_ASYNC.md 文件，清晰地说明如何启动新工作流、如何查看审核请求，以及如何编写回复文件来与系统互动。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 7
          }
        ]
      },
      {
        "id": 8,
        "title": "Task #1: 稳健的批量初筛",
        "description": "开发 run_batch_triage.py。核心要求：1. 实现批处理和检查点机制。2. 必须动态加载最新的事件Schema来执行分类。3. 输出单一的、待审核的 triage_pending_review.jsonl 文件。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 9,
        "title": "Task #2: 人类智慧网关 - 离线审核",
        "description": "开发审核辅助脚本 (prepare_review_file.py 和 process_review_results.py)，并定义清晰的CSV审核流程。目标是高效地将AI的初步分类转化为高质量的、经过人类校准的 final_known_events.jsonl 和 final_unknown_events.jsonl。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          8
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 10,
        "title": "Task #3: 知识增长引擎 - 交互式学习",
        "description": "开发 run_learning_workflow.py。该脚本读取 final_unknown_events.jsonl，通过人机交互指导 SchemaLearnerAgent 完成学习，并将新学会的Schema更新到核心的 event_schemas.json 文件中，为系统的下一次迭代提供增长。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          9
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 11,
        "title": "Task #4: 价值实现 - 批量抽取",
        "description": "开发 run_extraction_workflow.py。该脚本读取高质量的 final_known_events.jsonl，对所有已知事件进行批量化、结构化的信息抽取，产出可直接用于图谱构建的 structured_events.jsonl。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          9
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 12,
        "title": "Task #1: 奠定基石 - 建立中央状态库与配置文件",
        "description": "1. 设计并创建`master_state.db` (SQLite)，用于追踪每个数据点的生命周期状态。2. 创建唯一的`config.yaml`中央配置文件，管理所有路径、批次大小、模型名称等参数。3. 开发一个所有其他脚本都将引用的配置加载模块。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 13,
        "title": "Task #2: 实施第一阶段 - 开发与状态库集成的批量初筛工作流",
        "description": "开发`run_batch_triage.py`。它必须：1. 从`config.yaml`读取配置。2. 从`master_state.db`查询状态为`pending_triage`的数据。3. 在分类时引入置信度分数。4. 将分类结果和置信度写回`master_state.db`，并更新状态为`pending_review`。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          12
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 14,
        "title": "Task #3: 实施第二阶段 - 开发支持优先级的离线人工审核工作流",
        "description": "开发审核辅助脚本。`prepare_review_file.py`需从数据库查询待审核数据，并根据置信度排序生成CSV。`process_review_results.py`需读取审核后的CSV，并将最终结果更新回`master_state.db`，设置状态为`pending_learning`或`pending_extraction`。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          13
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 15,
        "title": "Task #4: 实施第三阶段 - 开发增强型交互式学习工作流",
        "description": "开发`run_learning_workflow.py`。它必须：1. 从数据库查询待学习数据。2. 实现更丰富的交互指令(如`show_samples`, `merge_clusters`)。3. 在学会新Schema后，将`event_schemas.json`更新，并把对应数据的状态在数据库中重置为`pending_triage`，以闭合知识循环。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          14
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 16,
        "title": "Task #5: 实施第四阶段 - 开发批量抽取工作流",
        "description": "开发`run_extraction_workflow.py`。它从`master_state.db`查询状态为`pending_extraction`的数据，进行批量抽取，并将最终的结构化数据存入指定位置，同时在数据库中将任务状态更新为`completed`。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          14
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 17,
        "title": "系统优化与文档完善",
        "description": "对系统进行持续优化，并创建和维护关键技术文档，以提高项目的可维护性和可理解性。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          16
        ],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "创建Prompt调优指南",
            "description": "创建 PROMPT_TUNING_GUIDE.md 文件，详细说明所有LLM调用场景、目标、提示词和预期输出，为模型优化和选型提供依据。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 17
          }
        ]
      },
      {
        "id": 18,
        "title": "Task #18: 实现关系分析与知识存储层",
        "description": "实现一个全新的处理层，负责分析已抽取事件之间的逻辑关系，并将事件节点和关系边持久化地存储到双数据库（图数据库和向量数据库）中，为构建知识图谱奠定基础。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          17
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "V4.0详细设计规划 - 关系分析与知识存储",
            "description": "根据架构师与管理者的讨论，Task #18的具体实现细节如下：1. **新工作流**: 创建`run_relationship_analysis.py`作为抽取后的新阶段。2. **关系分析**: `RelationshipAnalysisToolkit`将使用LLM分析事件间的关系，关系类型体系定义为：`Causal` (因果), `Temporal` (时序), `Sub-event` (从属), `Elaboration` (阐述), `Contradiction` (矛盾), `Influence` (影响), `Related` (相关)。3. **图存储**: `GraphStorageAgent`负责将事件、实体节点和关系边写入图数据库。4. **向量存储**: `VectorStorageAgent`负责实现分层向量化策略，对`_source_text` (原文), `event.description` (事件描述), 和构造的`entity_centric_context` (实体中心上下文) 分别进行向量化并存入ChromaDB。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 18
          }
        ]
      },
      {
        "id": 19,
        "title": "Task #19: 开发混合检索器并闭合知识循环",
        "description": "开发一个能够同时查询图数据库和向量数据库的混合检索器（HybridRetrieverAgent），并将其集成到现有的抽取和分析工作流中，通过为LLM提供丰富的历史上下文来增强其处理精度，从而闭合知识反馈循环。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          18
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "V4.0详细设计规划 - 混合检索与知识闭环",
            "description": "根据架构师与管理者的讨论，Task #19的具体实现细节如下：1. **触发时机**: 优先在`run_relationship_analysis.py`工作流中引入混合检索。2. **核心Agent**: 实现`HybridRetrieverAgent`作为“情报分析师”。3. **检索策略**: Agent需对新文本进行初步实体识别，然后**并行**查询双数据库：a) **图数据库**: 基于核心实体进行精确的、结构化的关系与事件查询。b) **向量数据库**: 基于全文向量进行模糊的、语义相似的事件案例查询。4. **上下文整合与Prompt增强**: Agent将检索到的图谱事实和相似案例整合成一段简洁的“背景摘要”，并将其注入到关系分析任务的Prompt中，为LLM提供决策参考，实现知识闭环。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 19
          }
        ]
      },
      {
        "id": 20,
        "title": "Task #20: 并行执行全量数据的初步事件抽取",
        "description": "为了提高项目效率，在V4.0的关系分析与知识图谱功能开发的同时，并行地对全量数据（来自IC_data/filtered_data.json）执行初步的事件抽取。此任务的目标是生成一个临时的、包含所有原子事件的structured_events.jsonl文件，为后续的知识图谱构建提供原材料，并提前暴露Prompt在多样化数据上的表现。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          19
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 21,
        "title": "Task #21: 对10%初步事件抽取结果进行全面分析与技术验证",
        "description": "基于已完成的10%全量数据抽取结果（docs/output/structured_events.jsonl），执行一次全面的初步分析与处理，旨在校验数据质量、摸清数据特征，并对后续核心任务（Task #18, #19）进行技术原型验证。分析内容包括：1. 数据质量与完整性校验；2. 核心实体与关系分析；3. 事件类型与分布分析；4. 定量数据解析；5. 构建微型知识图谱与向量检索原型，为V4.0的开发扫清障碍。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "medium",
        "subtasks": [
          {
            "id": 1,
            "title": "数据质量审查与特征分析",
            "description": "定量地、全面地理解我们初步抽取的数据质量和内在特征，发现潜在的数据问题和关键模式。具体包括：1. 创建`src/analysis/extraction_quality_analyzer.py`。2. 执行完整性校验、事件类型分布分析、高频实体分析和定量数据探查。3. 输出一份分析报告。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 21
          },
          {
            "id": 2,
            "title": "构建微型知识图谱原型",
            "description": "验证将扁平的事件JSONL数据转化为相互关联的图结构的可行性。具体包括：1. 创建原型脚本`src/analysis/build_micro_graph.py`。2. 使用`networkx`在内存中构建图，将事件和实体创建为节点，并创建它们之间的关系边。3. 为`GraphStorageAgent`的开发提供一个经过验证的图数据模型。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 21
          },
          {
            "id": 3,
            "title": "构建微型向量数据库原型",
            "description": "完整实现并验证需求文档中定义的“分层向量化策略”。具体包括：1. 增强`src/analysis/vector_search_prototype.py`。2. 使用`ChromaDB`，对每个事件生成并存储三种不同的向量表示：事件描述、实体中心上下文、原文片段。3. 为`VectorStorageAgent`的开发提供可以直接复用的代码。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 21
          },
          {
            "id": 4,
            "title": "开发混合检索原型并闭合验证循环",
            "description": "模拟`HybridRetrieverAgent`的核心逻辑，证明结合图的精确查询和向量的模糊查询能产生更优越的检索结果。具体包括：1. 创建原型脚本`src/analysis/hybrid_retrieval_prototype.py`。2. 协同调用图谱和向量原型。3. 实现一个演示混合检索流程并输出融合结果的脚本，为`HybridRetrieverAgent`的开发提供逻辑蓝图。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 21
          }
        ]
      },
      {
        "id": 22,
        "title": "优化抽取Prompt以捕获结构化定量数据",
        "description": "当前抽取流程无法将description中包含的金额、百分比、日期等信息有效提取到结构化的`quantitative_data`字段中。此任务的目标是：1. 分析`prompts/extraction.md`和相关抽取器代码，定位问题根源。2. 修改并优化Prompt，使其能够准确解析并填充`quantitative_data`字段。3. 通过小批量数据验证修复效果。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "验证Prompt修复效果",
            "description": "使用小批量数据（例如，从 `IC_data/filtered_data.json` 中选取5-10条包含明确数量信息的样本）运行一次 `run_extraction_workflow.py`，并人工检查输出的 `structured_events.jsonl` 文件，确认 `quantitative_data` 字段是否已按预期被正确填充。",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 22
          }
        ]
      },
      {
        "id": 23,
        "title": "建立LLM调用的健壮性与可追溯性规范",
        "description": "此为一项规范型任务，定义了所有模块在调用大语言模型（LLM）时必须遵守的核心准则。要求：1. **保留原始输出**：完整记录LLM返回的原始数据。2. **分离解析结果**：使用try-except处理返回内容，成功的结果进入主数据流，失败的案例（含原始数据、错误信息等）必须记录到专门的“失败审查”位置（如独立的日志文件或数据表）。3. **关联ID**: 所有记录必须包含唯一的请求ID以便追溯。此规范将作为未来所有LLM相关功能开发的验收标准。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 24,
        "title": "Task #21.1: 创建 Cortex 模块基础架构",
        "description": "创建 `run_cortex_workflow.py` 脚本文件和 `src/cortex/` 目录。定义核心组件的类骨架 (`VectorizationService`, `ClusteringOrchestrator`, `RefinementAgent`)。这是Cortex模块的初始化步骤。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 25,
        "title": "Task #21.2: 实现 ClusteringOrchestrator 的算法粗聚类功能",
        "description": "实现从数据库读取待处理事件、调用向量化服务、计算实体加权距离、并使用DBSCAN算法进行聚类的核心逻辑。将聚类结果（`event_id` -> `cluster_id`）写入数据库。依赖 Task #21.1。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          24
        ],
        "priority": "high",
        "subtasks": [
          {
            "id": 1,
            "title": "Refactor vectorization to use local model",
            "description": "Refactor VectorizationService and related components to use a local sentence-transformers model instead of relying on an LLMClient for embeddings. This involves making the workflow synchronous.",
            "details": "",
            "status": "done",
            "dependencies": [],
            "parentTaskId": 25
          }
        ]
      },
      {
        "id": 26,
        "title": "Task #21.3: 实现 RefinementAgent 的基础精炼功能",
        "description": "实现处理小规模“粗簇”的逻辑。开发 \"Refinement Prompt\"，调用LLM对簇进行分析，并返回“故事单元”。依赖 Task #21.1。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          24
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 27,
        "title": "Task #21.4: 实现 RefinementAgent 的大簇处理策略",
        "description": "实现“摘要-检索-扩展”的迭代逻辑，以处理规模超过预设阈值的“粗簇”。依赖 RefinementAgent 的基础功能。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          26
        ],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 28,
        "title": "Task #21.5: 实现 Cortex 的批处理触发机制",
        "description": "修改 `run_extraction_workflow.py`，在脚本末尾添加 `check_and_trigger_cortex` 函数，实现基于阈值的自动调用。",
        "details": "",
        "testStrategy": "",
        "status": "pending",
        "dependencies": [],
        "priority": "low",
        "subtasks": []
      },
      {
        "id": 29,
        "title": "Task #21.6: 整合并测试端到端 Cortex 工作流",
        "description": "将所有组件整合到 `run_cortex_workflow.py` 中，并进行完整的端到端测试，确保从事件输入到生成“故事单元”状态的流程完全通畅。依赖粗聚类和精炼功能的完成。",
        "details": "",
        "testStrategy": "",
        "status": "done",
        "dependencies": [
          25,
          27
        ],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 30,
        "title": "执行全量数据事件抽取并监控完成情况",
        "description": "此任务用于追踪 `run_extraction_workflow.py` 在全量数据集上的执行过程。主要工作是监控其进度，确保其顺利完成，并处理在运行过程中可能出现的任何问题。",
        "details": "",
        "testStrategy": "",
        "status": "in-progress",
        "dependencies": [],
        "priority": "medium",
        "subtasks": []
      },
      {
        "id": 31,
        "title": "Task #31: 验证并完善知识迭代闭环",
        "description": "此任务旨在将我们在需求文档V4.0（4.7节）中定义的“知识迭代闭环”策略在代码层面完全实现并进行端到端验证。核心是确保系统在学会新知识后，能够自动将相关数据重新纳入处理流程，实现知识的自我增强。",
        "details": "1. **检查 `run_learning_workflow.py`**: 审查并确保该脚本在成功学习并保存新Schema后，会自动将所有相关的 `pending_learning` 事件状态重置为 `pending_triage`。\n2. **准备测试数据**: 从主数据集中选取或构造一小批（约50-100条）代表了某种新事件模式的“未知事件”，并手动将它们的状态在数据库中设置为 `pending_learning`。\n3. **执行学习工作流**: 运行 `run_learning_workflow.py`，与系统交互，完成新Schema的定义和保存。\n4. **验证状态重置**: 学习完成后，检查数据库，确认之前用于学习的事件状态是否已全部变回 `pending_triage`。\n5. **执行初筛工作流**: 运行 `run_batch_triage.py`，验证 `TriageAgent` 现在是否能够利用新学会的Schema，成功地将这些事件分类，并将其状态更新为 `pending_extraction`。\n6. **编写总结报告**: 将整个验证过程、结果和发现的问题记录在一份简短的Markdown报告中。",
        "testStrategy": "1. 单元测试：为 `run_learning_workflow.py` 中负责重置状态的函数编写单元测试。\n2. 集成测试：创建一个小型的测试数据库，模拟完整的“学习 -> 状态重置 -> 重新初筛”流程。\n3. 端到端验证：按照“实施细节”中的步骤进行完整的手动测试，并记录结果。",
        "status": "pending",
        "dependencies": [],
        "priority": "high",
        "subtasks": []
      },
      {
        "id": 32,
        "title": "Task #32: 构建统一的系统管理CLI",
        "description": "当前系统由多个独立的Python脚本驱动，操作流程分散，对用户不友好。此任务旨在创建一个统一的命令行接口（CLI），将所有核心工作流（如初筛、学习、抽取、Cortex、关系分析）封装成子命令，提供一个单一的、专业的系统管理入口。",
        "details": "1. **选择CLI框架**: 采用 `argparse` 或更高级的库（如 `click` 或 `typer`）来构建CLI应用。\n2. **创建主入口脚本**: 创建一个新的主脚本，例如 `main.py` 或 `manage.py`。\n3. **封装工作流**: 将 `run_batch_triage.py`, `run_learning_workflow.py`, `run_extraction_workflow.py`, `run_cortex_workflow.py`, `run_relationship_analysis.py` 的核心逻辑封装成可以被主脚本调用的函数。\n4. **设计子命令**:\n   - `main.py triage`: 运行批量初筛工作流。\n   - `main.py learn`: 运行交互式学习工作流。\n   - `main.py extract`: 运行事件抽取工作流。\n   - `main.py cortex`: 手动触发Cortex故事发现工作流。\n   - `main.py analyze`: 运行关系分析与存储工作流。\n   - `main.py run-all`: 按正确顺序自动依次执行所有工作流。\n5. **添加辅助功能**: 在CLI中加入 `--help` 说明，并为每个子命令提供清晰的文档。\n6. **更新项目文档**: 更新 `README.md` 或创建一个新的 `CLI_GUIDE.md`，说明如何使用这个新的管理工具。",
        "testStrategy": "1. 为每个子命令编写独立的集成测试，验证其是否能成功调用正确的工作流。\n2. 手动测试所有CLI命令及其组合，确保其行为符合预期。\n3. 检查 `--help` 输出的清晰度和准确性。",
        "status": "pending",
        "dependencies": [
          31
        ],
        "priority": "medium",
        "subtasks": []
      }
    ],
    "metadata": {
      "created": "2025-07-16T12:53:46.081Z",
      "updated": "2025-08-02T11:17:58.759Z",
      "description": "Tasks for master context"
    }
  }
}