#!/usr/bin/env python3
"""
ç»•è¿‡LLMClientçš„ä¸´æ—¶Cortexè¿è¡Œè„šæœ¬
"""
import os
import requests
import json
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.core.config_loader import load_config, get_config
from src.core.database_manager import DatabaseManager

def direct_llm_call(prompt, model="deepseek-ai/DeepSeek-V2.5"):
    """ç›´æ¥è°ƒç”¨APIï¼Œç»•è¿‡é¡¹ç›®çš„LLMClient"""
    api_key = os.getenv('SILICONFLOW_API_KEY')
    if not api_key:
        raise ValueError("éœ€è¦SILICONFLOW_API_KEYç¯å¢ƒå˜é‡")
    
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1000,
        "temperature": 0.7
    }
    
    response = requests.post(url, headers=headers, json=data, timeout=30)
    
    if response.status_code == 200:
        result = response.json()
        return result['choices'][0]['message']['content']
    else:
        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

def simple_event_clustering():
    """ç®€åŒ–ç‰ˆäº‹ä»¶èšç±»å¤„ç†"""
    print("ğŸš€ å¼€å§‹ç®€åŒ–ç‰ˆCortexå¤„ç†\n")
    
    # åŠ è½½é…ç½®å’Œæ•°æ®åº“
    config_path = project_root / "config.yaml"
    load_config(config_path)
    config = get_config()
    
    db_path = config.get('database', {}).get('path')
    db_manager = DatabaseManager(db_path)
    
    # è·å–å¾…èšç±»äº‹ä»¶
    print("ğŸ“Š è·å–å¾…èšç±»äº‹ä»¶...")
    events_df = db_manager.get_records_by_status_as_df('pending_clustering')
    
    if events_df.empty:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¾…èšç±»äº‹ä»¶")
        return
    
    print(f"âœ… æ‰¾åˆ° {len(events_df)} æ¡å¾…èšç±»äº‹ä»¶")
    
    # å¤„ç†å°æ‰¹é‡äº‹ä»¶ï¼ˆé¿å…ä¸€æ¬¡æ€§å¤„ç†å¤ªå¤šï¼‰
    batch_size = 5
    processed = 0
    
    for i in range(0, min(batch_size, len(events_df))):
        try:
            event = events_df.iloc[i]
            event_id = event['id']
            source_text = event['source_text'][:500]  # æˆªå–å‰500å­—ç¬¦
            
            print(f"\nğŸ”„ å¤„ç†äº‹ä»¶ {i+1}/{batch_size}: {event_id[:8]}...")
            
            # æ„å»ºç®€å•çš„æ•…äº‹æ€»ç»“prompt
            prompt = f"""
è¯·ä¸ºä»¥ä¸‹äº‹ä»¶ç”Ÿæˆä¸€ä¸ªç®€çŸ­çš„æ•…äº‹æ‘˜è¦ï¼ˆ1-2å¥è¯ï¼‰ï¼š

äº‹ä»¶å†…å®¹ï¼š{source_text}

è¯·ç›´æ¥å›å¤æ‘˜è¦å†…å®¹ï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šã€‚
"""
            
            # è°ƒç”¨APIç”Ÿæˆæ‘˜è¦
            summary = direct_llm_call(prompt)
            print(f"ğŸ“ æ‘˜è¦: {summary[:100]}...")
            
            # ç”Ÿæˆæ•…äº‹IDå¹¶æ›´æ–°æ•°æ®åº“
            import uuid
            story_id = f"story_{uuid.uuid4().hex[:8]}"
            
            # æ›´æ–°æ•°æ®åº“çŠ¶æ€
            db_manager.update_story_info(event_id, story_id, summary[:200])
            db_manager.update_status(event_id, 'pending_relationship_analysis')
            
            processed += 1
            print(f"âœ… äº‹ä»¶å¤„ç†å®Œæˆï¼Œæ•…äº‹ID: {story_id}")
            
        except Exception as e:
            print(f"âŒ äº‹ä»¶å¤„ç†å¤±è´¥: {e}")
            continue
    
    print(f"\nğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆ! æˆåŠŸå¤„ç† {processed} æ¡äº‹ä»¶")
    print("ğŸ“ˆ è¿™äº›äº‹ä»¶å·²å‡†å¤‡å¥½è¿›è¡Œå…³ç³»åˆ†æ")
    
    return processed

def main():
    try:
        processed_count = simple_event_clustering()
        
        if processed_count and processed_count > 0:
            print(f"\nâœ… ä¸´æ—¶Cortexå¤„ç†æˆåŠŸ!")
            print(f"ğŸ“Š å¤„ç†äº‹ä»¶æ•°: {processed_count}")
            print("ğŸ”„ ä¸‹ä¸€æ­¥å¯ä»¥è¿è¡Œå…³ç³»åˆ†æå·¥ä½œæµ")
        else:
            print("\nâš ï¸ æœªå¤„ç†ä»»ä½•äº‹ä»¶")
            
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
