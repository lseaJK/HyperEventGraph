# run_prompt_tuning_examples.py
"""
A self-contained and reliable script to generate concrete examples for each of the 
three core LLM-driven tasks: Triage, Schema Generation, and Event Extraction.

This script directly implements the prompt templating logic and uses real data
to produce authentic prompts for tuning and evaluation.
"""
import asyncio
import json
from pathlib import Path
import sys
import random

# Add project root to sys.path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.core.config_loader import load_config
from src.llm.llm_client import LLMClient

# --- Helper to print formatted sections ---
def print_section(title, prompt, result):
    print("\n" + "="*80)
    print(f"ğŸ¬ SCENARIO: {title}")
    print("="*80)
    print("\n--- PROMPT SENT TO LLM ---\n")
    print(prompt)
    print("\n--- LLM JSON RESPONSE ---\n")
    try:
        # Pretty-print the JSON response
        parsed_json = json.loads(result)
        print(json.dumps(parsed_json, indent=2, ensure_ascii=False))
    except (json.JSONDecodeError, TypeError):
        print(result if result else "None")
    print("\n" + "="*80)

# --- Prompt Generation Logic (copied and adapted from source code) ---

def get_triage_prompt(text_sample: str, event_types: list) -> str:
    event_types_str = "\n- ".join(event_types)
    domains_str = "\n- ".join(["financial", "circuit", "general"]) # Example domains
    
    return f"""
You are a Triage Agent responsible for classifying event types and their domains.

CRITICAL INSTRUCTIONS:
1. You MUST output ONLY a valid JSON object - nothing else.
2. DO NOT include any explanatory text before or after the JSON.
3. DO NOT use XML tags, markdown, or any other formatting.
4. DO NOT mention tools or function calls.

Your output format MUST be exactly:
{{"status": "known", "domain": "äº‹ä»¶é¢†åŸŸ", "event_type": "äº‹ä»¶ç±»å‹", "confidence": 0.95}}

æˆ–è€…:
{{"status": "unknown", "event_type": "Unknown", "domain": "unknown", "confidence": 0.99}}

IMPORTANT: If you output anything other than a pure JSON object, the system will fail.

Here are the domains you can recognize:
- {domains_str}

Here are the event types you can recognize:
- {event_types_str}

Analyze the provided text, determine the most appropriate domain and event type, and then output ONLY the JSON classification.

--- TEXT TO ANALYZE ---
{text_sample}
"""

def get_schema_gen_prompt(text_samples: list) -> str:
    sample_block = "\n".join([f"- \"{s}\"" for s in text_samples])
    return f"""
You are an expert data architect. Your task is to analyze text samples describing a specific event type and create a concise JSON schema.

**Instructions:**
1.  **Analyze Samples:** Understand the common theme.
2.  **Create Schema:** Generate a JSON object with "schema_name", "description", and "properties".
    -   `schema_name`: PascalCase:PascalCase format (e.g., "Company:ProductLaunch").
    -   `description`: A one-sentence explanation.
    -   `properties`: A dictionary of snake_case keys with brief descriptions.
3.  **Output:** Your entire output must be a single, valid JSON object.

**Text Samples:**
{sample_block}

**Example Output:**
{{
  "schema_name": "Company:LeadershipChange",
  "description": "Describes the appointment or departure of a key executive.",
  "properties": {{
    "company": "The company involved.",
    "executive_name": "The name of the executive.",
    "new_role": "The new position or title."
  }}
}}
"""

def get_extraction_prompt(text_sample: str) -> str:
    event_title = event_schema.get("title", "æœªçŸ¥äº‹ä»¶")
    event_description = event_schema.get("description", "æ— æè¿°")
    
    return f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„ä¿¡æ¯æŠ½å–ç³»ç»Ÿï¼Œä¸“æ³¨äºä»é›†æˆç”µè·¯ï¼ˆSemiconductorï¼‰å’Œç›¸å…³äº§ä¸šé¢†åŸŸçš„æ–°é—»ã€å…¬å‘Šã€ç ”ç©¶æŠ¥å‘Šä¸­è¯†åˆ«**å·²å‘ç”Ÿçš„æ˜ç¡®ä¿¡æ¯æ„æˆçš„ç»“æ„åŒ–äº‹ä»¶**ã€‚

---

### ğŸ¯ ä»»åŠ¡ç›®æ ‡ï¼š

è¯·ä»è¾“å…¥æ–‡æœ¬ä¸­æŠ½å–**ä¸€ä¸ªæˆ–å¤šä¸ªå·²å‘ç”Ÿçš„äº‹å®äº‹ä»¶**ï¼Œå¹¶æŒ‰å¦‚ä¸‹ JSON ç»“æ„è¾“å‡ºã€‚æ¯ä¸ªäº‹ä»¶ä½œä¸ºç‹¬ç«‹å¯¹è±¡ï¼Œç»Ÿä¸€è¿”å›ä¸º JSON æ•°ç»„ã€‚

---

### ğŸ§± æŠ½å–ç»´åº¦è¯´æ˜ï¼š

æ¯ä¸ªäº‹ä»¶å¿…é¡»åŒ…æ‹¬ä»¥ä¸‹å­—æ®µï¼ˆæŸäº›ä¸ºå¯é€‰ï¼‰ï¼š

| å­—æ®µå | ç±»å‹  | æè¿°  |
| --- | --- | --- |
| `event_type` | string | äº‹ä»¶ä¸»ç±»ï¼Œä¾‹å¦‚ï¼šMarketAction, SupplyChainDisruption, PolicyChange ç­‰ |
| `micro_event_type` | string | æ›´ç»†ç²’åº¦çš„äº‹ä»¶ç±»å‹ï¼Œå¦‚ï¼šPriceReduction, CapacityChange, RevenueDrop ç­‰ |
| `event_date` | string or null | äº‹ä»¶å‘ç”Ÿæ—¶é—´ï¼Œå¦‚ `"2023-Q1"`ã€`"2023-H2"`ã€`"2025-07-30"`ï¼Œä¸æ˜ç¡®åˆ™è®¾ä¸º `null` |
| `description` | string | ç”¨è‡ªç„¶è¯­è¨€ç®€è¦æè¿°è¯¥äº‹ä»¶ï¼ˆä¸è¦æ··å…¥é¢„æµ‹ï¼‰ |
| `involved_entities` | array | æ¶‰åŠçš„ä¼ä¸šã€æœºæ„ã€å›¢ä½“ |
| `quantitative_data` | object or null | è‹¥äº‹ä»¶ä¸­æåˆ°é‡åŒ–æŒ‡æ ‡ï¼ˆå¦‚ä»·æ ¼ã€æ”¶å…¥ã€åˆ©ç”¨ç‡ï¼‰åˆ™å¡«å†™ |
| `forecast` | null | **ä¸€å¾‹ä¸º nullï¼Œå› ä¸ºä¸æŠ½å–é¢„æµ‹ç±»äº‹ä»¶** |

---

### ğŸ“Œ event_type æ¨èå€¼ï¼š

- `"MarketAction"`ï¼šå¸‚åœºè¡Œä¸ºï¼Œå¦‚é™ä»·ã€æ¶¨ä»·ã€è¥æ”¶å˜åŠ¨
  
- `"SupplyChainDisruption"`ï¼šä¾›åº”é“¾å¹²æ‰°ï¼Œå¦‚åº“å­˜ã€äº§èƒ½é—®é¢˜
  
- `"PolicyChange"`ï¼šæ”¿ç­–å˜æ›´ï¼ˆå‡ºå£ç®¡åˆ¶ã€è¡¥è´´ç­‰ï¼‰
  
- `"ExecutiveChange"`ï¼šé«˜ç®¡å˜åŠ¨
  
- `"Partnership"`ï¼šå…¬å¸åˆä½œæˆ–å¹¶è´­
  
- `"LegalRegulation"`ï¼šæ³•å¾‹/åˆè§„ç›¸å…³åŠ¨ä½œ
  
- `"Other"`ï¼šå…¶ä»–æ˜ç¡®å®šä¹‰çš„å·²å‘ç”Ÿäº‹ä»¶
  

---

### ğŸ“Œ micro_event_type ç¤ºä¾‹ï¼ˆæ ¹æ® event_type å†³å®šï¼‰ï¼š

- `InventoryAdjustment`
  
- `CapacityChange`
  
- `RevenueDrop`
  
- `PriceReduction`
  
- `PriceStability`
  
- `ProductionDelay`
  
- `ExecutiveDeparture`
  
- `JointVenture`
  
- `ExportRestriction`
  

---

### ğŸ“Œ ç‰¹åˆ«è¦æ±‚ï¼ˆæ ¸å¿ƒæŠ½å–é™åˆ¶ï¼‰ï¼š

> ğŸš« **ç»å¯¹ç¦æ­¢æŠ½å–é¢„æµ‹ç±»ã€è§‚ç‚¹ç±»ã€æ¨æµ‹ç±»å†…å®¹ä¸ºäº‹ä»¶ã€‚**
> 
> - åŒ…å«â€œé¢„è®¡â€ã€â€œä¼°è®¡â€ã€â€œé¢„æµ‹â€ã€â€œæå°†â€ã€â€œå¯èƒ½â€ã€â€œæœ‰æœ›â€ç­‰è¡¨è¾¾çš„ä¿¡æ¯**ä¸€å¾‹å¿½ç•¥**ï¼Œä¸è¾“å‡ºç»“æ„åŒ–äº‹ä»¶ã€‚
>   
> - åªä¿ç•™**å®¢è§‚ã€å·²å‘ç”Ÿçš„ã€æ˜ç¡®ä¿¡æ¯æ„æˆçš„è¡Œä¸ºæˆ–ç»“æœ**ã€‚
>   
> - `forecast` å­—æ®µåœ¨æ‰€æœ‰äº‹ä»¶ä¸­å¿…é¡»è®¾ä¸º `null`ã€‚
>   

---

### ğŸ“Œ è¾“å‡ºæ ¼å¼ï¼š

- è¿”å›æ ¼å¼å¿…é¡»ä¸ºä¸€ä¸ª JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªäº‹ä»¶å¯¹è±¡ã€‚
  
- æ¯ä¸ªäº‹ä»¶å¯¹è±¡å¿…é¡»éµå®ˆå¦‚ä¸‹ç»“æ„ï¼š
  

```json
{ "event_type": "string", "micro_event_type": "string", "event_date": "string or null", "description": "string", "involved_entities": [ { "entity_name": "string", "entity_type": "Company | GovernmentAgency | IndustryGroup | ResearchAgency | IndustryExpert | Other", "role_in_event": "string or null" } ], "quantitative_data": { "metric": "string or null", "value": "number or string", "unit": "string or null", "change_rate": "number or null", "period": "string or null" } or null, "forecast": null }
```

---

### âœ… ç¤ºä¾‹è¾“å…¥ï¼ˆè¯·ä¸¥æ ¼åŸºäºæ­¤é£æ ¼è¾“å‡ºï¼‰

> ã€Šç§‘åˆ›æ¿æ—¥æŠ¥ã€‹24æ—¥è®¯ï¼Œæ™¶åœ†ä»£å·¥ä¸šä¸‹åŠå¹´å±•æœ›é»¯æ·¡ï¼ŒICè®¾è®¡ä¸šè€…é€éœ²ï¼Œç›®å‰é™¤äº†å°ç§¯ç”µä»åšå®ˆä»·æ ¼ä¹‹å¤–ï¼Œå…¶ä»–æ™¶åœ†ä»£å·¥å‚éƒ½å·²æœ‰ä¸åŒç¨‹åº¦ä¸å½¢å¼é™ä»·ï¼Œè‡ªå»å¹´ä¸‹åŠå¹´åº“å­˜ä¿®æ­£æ½®ä»¥æ¥ï¼Œæ™¶åœ†ä»£å·¥ä»·é™å¹…çº¦15%è‡³20%ã€‚ä¸šç•Œäººå£«ä¼°è®¡ï¼Œç°é˜¶æ®µæ™¶åœ†ä»£å·¥å‚æˆç†Ÿåˆ¶ç¨‹äº§èƒ½åˆ©ç”¨ç‡ä»ä½ï¼Œåç»­æå¿…é¡»ç¥­å‡ºæ›´å¤šé™ä»·ä¼˜æƒ ï¼Œæ‰èƒ½å¡«è¡¥äº§èƒ½ã€‚

---

### âœ… ç¤ºä¾‹è¾“å‡ºï¼ˆåªä¿ç•™å·²å‘ç”Ÿçš„äº‹ä»¶ï¼‰ï¼š

```json
[ { "event_type": "SupplyChainDisruption", "micro_event_type": "InventoryAdjustment", "event_date": "2023-H2", "description": "è‡ª2023å¹´ä¸‹åŠå¹´åº“å­˜ä¿®æ­£æ½®å¼€å§‹ï¼Œæ™¶åœ†ä»£å·¥å‚è¿›è¡Œåº“å­˜è°ƒæ•´ã€‚", "involved_entities": [ { "entity_name": "æ™¶åœ†ä»£å·¥å‚", "entity_type": "Company", "role_in_event": "ä¸»ä½“" } ], "quantitative_data": null, "forecast": null }, { "event_type": "MarketAction", "micro_event_type": "PriceReduction", "event_date": "2023-H2", "description": "è‡ª2023å¹´ä¸‹åŠå¹´ä»¥æ¥ï¼Œé™¤å°ç§¯ç”µå¤–çš„æ™¶åœ†ä»£å·¥å‚é™ä½æ™¶åœ†ä»£å·¥ä»·æ ¼ï¼Œé™å¹…çº¦15%è‡³20%ã€‚", "involved_entities": [ { "entity_name": "å…¶ä»–æ™¶åœ†ä»£å·¥å‚", "entity_type": "Company", "role_in_event": "ä¸»ä½“" }, { "entity_name": "ICè®¾è®¡ä¸šè€…", "entity_type": "IndustryGroup", "role_in_event": "ä¿¡æ¯æä¾›è€…" } ], "quantitative_data": { "metric": "Price", "value": null, "unit": "%", "change_rate": -17.5, "period": "since 2023-H2" }, "forecast": null }, { "event_type": "MarketAction", "micro_event_type": "PriceStability", "event_date": null, "description": "å°ç§¯ç”µç»´æŒæ™¶åœ†ä»£å·¥ä»·æ ¼ä¸å˜ã€‚", "involved_entities": [ { "entity_name": "å°ç§¯ç”µ", "entity_type": "Company", "role_in_event": "ä¸»ä½“" } ], "quantitative_data": null, "forecast": null }, { "event_type": "SupplyChainDisruption", "micro_event_type": "CapacityUtilizationLow", "event_date": null, "description": "æ™¶åœ†ä»£å·¥å‚æˆç†Ÿåˆ¶ç¨‹äº§èƒ½åˆ©ç”¨ç‡ä½ã€‚", "involved_entities": [ { "entity_name": "æ™¶åœ†ä»£å·¥å‚", "entity_type": "Company", "role_in_event": "ä¸»ä½“" }, { "entity_name": "ä¸šç•Œäººå£«", "entity_type": "IndustryExpert", "role_in_event": "è§‚å¯Ÿè€…" } ], "quantitative_data": { "metric": "Utilization Rate", "value": null, "unit": "%", "change_rate": null, "period": null }, "forecast": null } ]
```

---

**Text to analyze:**
---
{text_sample}
---

**Your JSON Output:**
"""

async def main():
    """Main function to run all examples."""
    print("Loading configuration from config.yaml...")
    load_config("config.yaml")
    
    print("Loading data from IC_data/filtered_data.json...")
    data_file = project_root / "IC_data" / "filtered_data.json"
    with open(data_file, 'r', encoding='utf-8') as f:
        all_texts = json.load(f)

    print("Loading schemas from output/schemas/event_schemas.json...")
    schema_file = project_root / "output" / "schemas" / "event_schemas.json"
    if schema_file.exists():
        with open(schema_file, 'r', encoding='utf-8') as f:
            all_schemas = json.load(f)
    else:
        print("Warning: Schema file not found. Using fallback schemas for examples.")
        all_schemas = {
            "Company:ExecutiveChange": {
                "title": "Company:ExecutiveChange", "description": "...",
                "properties": {"company": {}, "departing_executive": {}, "new_executive": {}, "role": {}}
            }
        }

    llm_client = LLMClient()

    # --- Scenario 1: Triage ---
    triage_sample = random.choice(all_texts)
    triage_prompt = get_triage_prompt(triage_sample, list(all_schemas.keys()))
    triage_result = await llm_client.get_raw_response(triage_prompt, task_type="triage")
    print_section("1. Batch Triage", triage_prompt, triage_result)

    # --- Scenario 2: Schema Generation ---
    schema_gen_samples = random.sample(all_texts, 3)
    schema_gen_prompt = get_schema_gen_prompt(schema_gen_samples)
    schema_gen_result = await llm_client.get_raw_response(schema_gen_prompt, task_type="schema_generation")
    print_section("2. Schema Generation", schema_gen_prompt, schema_gen_result)

    # --- Scenario 3: Event Extraction ---
    extraction_schema_name = "Company:ExecutiveChange"
    extraction_schema = all_schemas.get(extraction_schema_name)
    if not extraction_schema:
        extraction_schema_name = list(all_schemas.keys())[0]
        extraction_schema = all_schemas[extraction_schema_name]
        
    # Find a relevant text for the chosen schema
    extraction_sample = next((text for text in all_texts if "è¾ä»»" in text or "è‘£äº‹é•¿" in text or "CEO" in text), random.choice(all_texts))
    
    extraction_prompt = get_extraction_prompt(extraction_sample)
    extraction_result = await llm_client.get_raw_response(extraction_prompt, task_type="extraction")
    print_section(f"3. Event Extraction", extraction_prompt, extraction_result)

    print("\nâœ… All examples generated. Please review the prompts and responses for tuning.")

if __name__ == "__main__":
    asyncio.run(main())