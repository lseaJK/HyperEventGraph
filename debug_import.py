#!/usr/bin/env python3
"""
è°ƒè¯•ç‰ˆæœ¬çš„å¯¼å…¥è„šæœ¬
"""
import json
import hashlib
import sqlite3
from pathlib import Path

def debug_import(jsonl_file: str = "test_import.jsonl", db_path: str = "master_state.db"):
    """è¯¦ç»†è°ƒè¯•å¯¼å…¥è¿‡ç¨‹"""
    print(f"ğŸ” è°ƒè¯•å¯¼å…¥è¿‡ç¨‹...")
    
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line_no, line in enumerate(f, 1):
            print(f"\n=== å¤„ç†ç¬¬ {line_no} è¡Œ ===")
            
            data = json.loads(line.strip())
            print(f"åŸå§‹æ•°æ®é”®: {list(data.keys())}")
            
            # è·å–åŸæ–‡
            source_text = data.get('text', '')
            print(f"source_text é•¿åº¦: {len(source_text)}")
            if not source_text:
                print("âŒ è·³è¿‡ï¼šæ—  source_text")
                continue
            
            # ç”ŸæˆID
            record_id = hashlib.md5(source_text.encode()).hexdigest()
            print(f"record_id: {record_id}")
            
            # å‡†å¤‡ç»“æ„åŒ–æ•°æ®
            structured_data = {
                'quantitative_data': data.get('quantitative_data'),
                'event_date': data.get('event_date'),
                'description': data.get('description'),
                'micro_event_type': data.get('micro_event_type'),
                'forecast': data.get('forecast')
            }
            
            involved_entities = data.get('involved_entities', [])
            
            print(f"structured_data: {structured_data}")
            print(f"involved_entities: {involved_entities}")
            
            # JSON åºåˆ—åŒ–
            structured_json = json.dumps(structured_data, ensure_ascii=False)
            entities_json = json.dumps(involved_entities, ensure_ascii=False)
            
            print(f"structured_json: {structured_json}")
            print(f"entities_json: {entities_json}")
            
            # å‡†å¤‡æ’å…¥å‚æ•°
            insert_params = (
                record_id,
                source_text,
                'pending_clustering',
                1.0,
                data.get('event_type', 'unknown'),
                f'Imported event: {data.get("description", "")[:100]}...',
                structured_json,
                entities_json
            )
            
            print(f"æ’å…¥å‚æ•°é•¿åº¦: {len(insert_params)}")
            print(f"å‚æ•° 6 (structured_data): {insert_params[6]}")
            print(f"å‚æ•° 7 (involved_entities): {insert_params[7]}")
            
            # æ‰§è¡Œæ’å…¥
            try:
                cursor.execute("""
                    INSERT OR REPLACE INTO master_state 
                    (id, source_text, current_status, triage_confidence, assigned_event_type, notes, structured_data, involved_entities)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                """, insert_params)
                
                print(f"âœ… æ’å…¥æˆåŠŸï¼Œå½±å“è¡Œæ•°: {cursor.rowcount}")
                
                # ç«‹å³éªŒè¯
                cursor.execute("SELECT structured_data, involved_entities FROM master_state WHERE id = ?", (record_id,))
                verify_result = cursor.fetchone()
                print(f"éªŒè¯ç»“æœ: structured_data={verify_result[0]}, involved_entities={verify_result[1]}")
                
            except Exception as e:
                print(f"âŒ æ’å…¥å¤±è´¥: {e}")
            
            if line_no >= 1:  # åªå¤„ç†ç¬¬ä¸€è¡Œ
                break
    
    conn.commit()
    conn.close()

if __name__ == "__main__":
    debug_import()
