# HyperEventGraph å®Œæ•´å·¥ä½œæµæ¼”ç¤ºä¸æ–‡æ¡£

## ğŸ¯ é¡¹ç›®æ¦‚è¿°

HyperEventGraph æ˜¯ä¸€ä¸ªæ™ºèƒ½äº‹ä»¶å›¾è°±ç³»ç»Ÿï¼ŒåŒ…å«ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶ï¼š
- **A: æ”¹è¿›èšç±»ç­–ç•¥** - æ™ºèƒ½èšç±»ç®—æ³•ï¼ˆå…¬å¸ä¸»é¢˜ã€è¯­ä¹‰ä¸»é¢˜ï¼‰
- **B: ä¼˜åŒ–æµç¨‹** - æ‰¹é‡å¤„ç†ä¸å¢å¼ºAPI
- **C: èšç±»è¯„ä¼°** - TF-IDFè´¨é‡è¯„ä¼°ä¸äººå·¥QAæ”¯æŒ

## ğŸš€ å¿«é€Ÿæ¼”ç¤º (Demo)

### Demo 1: æœ€å°åŒ–æµ‹è¯•æµç¨‹ (5åˆ†é’Ÿ)

```bash
# 1. å¯¼å…¥æµ‹è¯•æ•°æ®
python simple_import.py test_import_20.jsonl

# 2. è¿è¡Œæ™ºèƒ½èšç±»
python run_smart_clustering.py --mode company --max_story_size 15

# 3. è¿è¡Œèšç±»è¯„ä¼°
python run_clustering_evaluation.py --group-by story_id --status pending_relationship_analysis --sample-per-group 2 --out-dir outputs

# 4. æŸ¥çœ‹ç»“æœ
ls -la outputs/
cat outputs/clustering_evaluation_report_*.json
```

**é¢„æœŸè¾“å‡ºï¼š**
- å¯¼å…¥ 9 æ¡äº‹ä»¶è®°å½•
- ç”Ÿæˆ 6-8 ä¸ªæ•…äº‹èšç±»
- ç”Ÿæˆ CSV æ ·æœ¬æ–‡ä»¶å’Œ JSON è¯„ä¼°æŠ¥å‘Š
- å†…èšæ€§åˆ†æ•°é€šå¸¸åœ¨ 0.5-0.8 ä¹‹é—´

### Demo 2: å®Œæ•´æµç¨‹æµ‹è¯• (15åˆ†é’Ÿ)

```bash
rm master_state.db
# 1. æ•°æ®å‡†å¤‡
python simple_import.py output/extraction/structured_events_0813.jsonl
python check_database_status.py

# # 2. æ‰¹é‡å¤„ç†
# python run_batch_triage.py  # Bç»„ä»¶ - ä¸‰çº§åˆ†æµ

# # 3. æŠ½å–å·¥ä½œæµ
# python run_extraction_workflow.py

# 4. èšç±»ï¼ˆé€‰æ‹©å…¶ä¸­ä¸€ç§æ–¹æ³•ï¼‰
# æ–¹æ³•A: æ™ºèƒ½èšç±» (æ¨èï¼ŒAç»„ä»¶æ”¹è¿›ç‰ˆ)
python run_smart_clustering.py --mode company --max_story_size 15
python run_smart_clustering.py --mode theme --max_story_size 20

# æ–¹æ³•B: Cortexç®€å•èšç±» (åŸºäºäº‹ä»¶ç±»å‹åˆ†ç»„)
# python run_cortex_workflow.py

# 5. å…³ç³»åˆ†æï¼ˆçœŸæ­£çš„å…³ç³»æŠ½å–ï¼‰
python run_relationship_analysis.py

# 6. å­¦ä¹ å·¥ä½œæµ
python run_learning_workflow.py

# 7. è´¨é‡è¯„ä¼° (Cç»„ä»¶)
python run_clustering_evaluation.py --group-by story_id --status pending_relationship_analysis --sample-per-group 3 --out-dir outputs

# 8. å¯åŠ¨APIæœåŠ¡ (Bç»„ä»¶)
python enhanced_api.py &
curl http://localhost:8080/api/status

# 9. æŸ¥çœ‹å®Œæ•´ç»“æœ
python check_database_status.py
ls -la outputs/
```

## ğŸ“š å®Œæ•´å·¥ä½œæµæ–‡æ¡£

### â— é‡è¦æ¾„æ¸…ï¼šCortex vs èšç±» vs å…³ç³»æŠ½å–

**å¸¸è§æ··æ·†è§£é‡Šï¼š**

1. **æ™ºèƒ½èšç±»** (`run_smart_clustering.py`) â‰  **Cortexèšç±»** (`run_cortex_workflow.py`)
   - è¿™æ˜¯ä¸¤ç§ä¸åŒçš„èšç±»ç®—æ³•
   - æ™ºèƒ½èšç±»ï¼šAç»„ä»¶çš„æ”¹è¿›æˆæœï¼Œå¤šç»´åº¦ç­–ç•¥ï¼ˆcompany/theme/hybridï¼‰
   - Cortexèšç±»ï¼šåŸºäºäº‹ä»¶ç±»å‹çš„ç®€å•åˆ†ç»„
   - **é€‰æ‹©å…¶ä¸­ä¸€ç§å³å¯ï¼Œä¸è¦åŒæ—¶è¿è¡Œ**

2. **èšç±»** â‰  **å…³ç³»æŠ½å–**
   - èšç±»ï¼šå°†ç›¸ä¼¼äº‹ä»¶åˆ†ç»„æˆæ•…äº‹ (`story_id`)
   - å…³ç³»æŠ½å–ï¼šåˆ†æäº‹ä»¶é—´çš„å…³ç³» (`run_relationship_analysis.py`)
   - **è¿™æ˜¯ä¸¤ä¸ªç‹¬ç«‹çš„æ­¥éª¤ï¼ŒæŒ‰é¡ºåºæ‰§è¡Œ**

3. **æ­£ç¡®çš„å·¥ä½œæµé¡ºåºï¼š**
   ```
   æ•°æ®å¯¼å…¥ â†’ ä¸‰çº§åˆ†æµ â†’ æŠ½å– â†’ èšç±»(äºŒé€‰ä¸€) â†’ å…³ç³»åˆ†æ â†’ å­¦ä¹  â†’ è¯„ä¼°
                                    â†“
                           æ™ºèƒ½èšç±» OR Cortexèšç±»
   ```

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

```
HyperEventGraph ç³»ç»Ÿæ¶æ„
â”œâ”€â”€ æ•°æ®å±‚
â”‚   â”œâ”€â”€ master_state.db (SQLiteä¸»æ•°æ®åº“)
â”‚   â”œâ”€â”€ IC_data/ (åŸå§‹æ•°æ®)
â”‚   â””â”€â”€ test_import_*.jsonl (æµ‹è¯•æ•°æ®)
â”œâ”€â”€ å¤„ç†å±‚
â”‚   â”œâ”€â”€ Aç»„ä»¶: æ™ºèƒ½èšç±»
â”‚   â”‚   â”œâ”€â”€ run_smart_clustering.py
â”‚   â”‚   â””â”€â”€ run_improved_cortex_workflow.py
â”‚   â”œâ”€â”€ Bç»„ä»¶: æµç¨‹ä¼˜åŒ–
â”‚   â”‚   â”œâ”€â”€ run_batch_triage.py
â”‚   â”‚   â”œâ”€â”€ enhanced_api.py
â”‚   â”‚   â””â”€â”€ å„ç§å·¥ä½œæµè„šæœ¬
â”‚   â””â”€â”€ Cç»„ä»¶: è´¨é‡è¯„ä¼°
â”‚       â”œâ”€â”€ run_clustering_evaluation.py
â”‚       â””â”€â”€ docs/clustering_evaluation_README.md
â”œâ”€â”€ æœåŠ¡å±‚
â”‚   â”œâ”€â”€ enhanced_api.py (REST API)
â”‚   â”œâ”€â”€ start_api_with_websocket.py (WebSocket)
â”‚   â””â”€â”€ frontend/ (Webç•Œé¢)
â””â”€â”€ é…ç½®å±‚
    â”œâ”€â”€ config.yaml (ä¸»é…ç½®)
    â”œâ”€â”€ model_config.yaml (æ¨¡å‹é…ç½®)
    â””â”€â”€ settings.yaml (ç³»ç»Ÿè®¾ç½®)
```

### ğŸ“Š æ•°æ®åº“çŠ¶æ€æœº

```
æ•°æ®æµçŠ¶æ€è½¬æ¢:
åŸå§‹æ–‡æœ¬ â†’ pending_extraction â†’ extracted â†’ pending_clustering 
â†’ clustered â†’ pending_relationship_analysis â†’ relationship_analyzed
â†’ pending_learning â†’ completed

æ³¨æ„ï¼šèšç±»æ­¥éª¤æœ‰ä¸¤ç§é€‰æ‹©ï¼Œä¸éœ€è¦åŒæ—¶è¿è¡Œï¼š
- æ™ºèƒ½èšç±» (run_smart_clustering.py) - æ¨èï¼ŒAç»„ä»¶æ”¹è¿›ç‰ˆ
- Cortexèšç±» (run_cortex_workflow.py) - åŸºäºäº‹ä»¶ç±»å‹çš„ç®€å•èšç±»
```

### ğŸ”§ è¯¦ç»†ç»„ä»¶è¯´æ˜

#### Aç»„ä»¶: æ”¹è¿›èšç±»ç­–ç•¥

**æ ¸å¿ƒè„šæœ¬ï¼š**
- `run_smart_clustering.py` - **æ™ºèƒ½èšç±»ä¸»è„šæœ¬ (æ¨è)**
  - ä¸“é—¨é’ˆå¯¹ç§‘åˆ›æ¿æ•°æ®çš„æ™ºèƒ½èšç±»
  - å¤šç»´åº¦èšç±»ç­–ç•¥ï¼ˆcompany/theme/hybridæ¨¡å¼ï¼‰
  - åŸºäºæŠ•èµ„åˆ†æéœ€æ±‚è®¾è®¡
- `run_cortex_workflow.py` - **Cortexç®€å•èšç±»**
  - åŸºäºäº‹ä»¶ç±»å‹çš„ç®€åŒ–èšç±»åˆ†ç»„
  - è¾ƒä¸ºç®€å•çš„èšç±»é€»è¾‘
- `run_improved_cortex_workflow.py` - æ”¹è¿›çš„Cortexå·¥ä½œæµ
- `run_enhanced_cortex_workflow.py` - å¢å¼ºCortexå·¥ä½œæµ

**âš ï¸ é‡è¦è¯´æ˜ï¼šèšç±»æ–¹æ³•é€‰æ‹©**
- **æ™ºèƒ½èšç±»** vs **Cortexèšç±»** æ˜¯ä¸¤ç§ä¸åŒçš„èšç±»æ–¹æ³•
- **ä¸éœ€è¦åŒæ—¶è¿è¡Œä¸¤ç§èšç±»**ï¼Œé€‰æ‹©å…¶ä¸­ä¸€ç§å³å¯
- **æ¨èä½¿ç”¨æ™ºèƒ½èšç±»** (`run_smart_clustering.py`)ï¼Œå› ä¸ºå®ƒæ›´é€‚åˆç§‘åˆ›æ¿æ•°æ®

**èšç±»æ¨¡å¼ï¼š**
```bash
# æ¨èï¼šæ™ºèƒ½èšç±»ï¼ˆAç»„ä»¶ä¸»è¦æˆæœï¼‰
# å…¬å¸ä¸»é¢˜èšç±» (åŸºäºå®ä½“å’Œå…¬å¸å)
python run_smart_clustering.py --mode company --max_story_size 15

# è¯­ä¹‰ä¸»é¢˜èšç±» (åŸºäºå†…å®¹ç›¸ä¼¼åº¦)
python run_smart_clustering.py --mode theme --max_story_size 20

# æ··åˆèšç±»
python run_smart_clustering.py --mode hybrid --max_story_size 12

# æˆ–è€…ï¼šCortexç®€å•èšç±»ï¼ˆåŸºäºäº‹ä»¶ç±»å‹åˆ†ç»„ï¼‰
# python run_cortex_workflow.py
```

**å‚æ•°è¯´æ˜ï¼š**
- `--mode`: èšç±»ç­–ç•¥ (company/theme/hybrid)
- `--max_story_size`: æ¯ä¸ªæ•…äº‹æœ€å¤§äº‹ä»¶æ•°
- `--min_cluster_size`: æœ€å°èšç±»å¤§å° (é»˜è®¤2)

#### Bç»„ä»¶: æµç¨‹ä¼˜åŒ–

**æ‰¹é‡å¤„ç†ï¼š**
```bash
# æ‰¹é‡ä¸‰çº§åˆ†æµ
python run_batch_triage.py --batch_size 50

# æ‰¹é‡æŠ½å–å·¥ä½œæµ
python run_extraction_workflow.py

# æ‰¹é‡å­¦ä¹ å·¥ä½œæµ
python run_learning_workflow.py
```

**APIæœåŠ¡ï¼š**
```bash
# å¯åŠ¨å¢å¼ºAPI
python enhanced_api.py

# ä¸»è¦ç«¯ç‚¹:
# GET /api/status - ç³»ç»ŸçŠ¶æ€
# GET /api/events - äº‹ä»¶åˆ—è¡¨
# POST /api/cluster - æ‰‹åŠ¨è§¦å‘èšç±»
# GET /api/graph - è·å–å›¾æ•°æ®
```

#### Cç»„ä»¶: èšç±»è¯„ä¼°

**è¯„ä¼°è„šæœ¬ï¼š**
```bash
# åŸºæœ¬è¯„ä¼°
python run_clustering_evaluation.py --group-by story_id --status pending_relationship_analysis

# è¯¦ç»†è¯„ä¼°
python run_clustering_evaluation.py \
  --group-by story_id \
  --status pending_relationship_analysis \
  --sample-per-group 5 \
  --min-group-size 2 \
  --out-dir evaluation_results
```

**è¯„ä¼°æŒ‡æ ‡ï¼š**
- **å†…èšæ€§ (Intra-cohesion)**: ç¾¤ä½“å†…éƒ¨ç›¸ä¼¼åº¦ (0-1, è¶Šé«˜è¶Šå¥½)
- **åˆ†ç¦»åº¦ (Inter-separation)**: ç¾¤ä½“é—´å·®å¼‚åº¦ (0-1, è¶Šä½è¶Šå¥½)  
- **Silhouetteåˆ†æ•°**: æ•´ä½“èšç±»è´¨é‡ (-1åˆ°1, è¶Šé«˜è¶Šå¥½)

**è¾“å‡ºæ–‡ä»¶ï¼š**
- `clustering_evaluation_samples_*.csv` - æ ·æœ¬æ•°æ® (äººå·¥QA)
- `clustering_evaluation_report_*.json` - é‡åŒ–æŒ‡æ ‡

### ğŸ”„ æ ‡å‡†å·¥ä½œæµç¨‹

#### æµç¨‹1: æ•°æ®å¯¼å…¥ä¸åˆå§‹åŒ–

```bash
# 1. æ¸…ç†ç¯å¢ƒ
python reset_event_status.py  # å¯é€‰ï¼Œé‡ç½®çŠ¶æ€

# 2. å¯¼å…¥æ•°æ®
# å°æ•°æ®é›†æµ‹è¯•:
python simple_import.py test_import_20.jsonl

# å¤§æ•°æ®é›†:
python init_database.py --data-file IC_data/filtered_data.json

# 3. éªŒè¯å¯¼å…¥
python check_database_status.py
python check_data_integrity.py
```

#### æµç¨‹2: æ ¸å¿ƒå¤„ç†

```bash
# 1. ä¸‰çº§åˆ†æµ (Bç»„ä»¶)
python run_batch_triage.py

# 2. æŠ½å–å·¥ä½œæµ
python run_extraction_workflow.py

# 3. èšç±»ï¼ˆé€‰æ‹©å…¶ä¸­ä¸€ç§æ–¹æ³•ï¼Œä¸è¦åŒæ—¶è¿è¡Œï¼‰
# æ–¹æ³•A: æ™ºèƒ½èšç±» (æ¨èï¼ŒAç»„ä»¶æ”¹è¿›ç‰ˆ)
python run_smart_clustering.py --mode company --max_story_size 15
python run_smart_clustering.py --mode theme --max_story_size 20

# æ–¹æ³•B: Cortexç®€å•èšç±» (åŸºäºäº‹ä»¶ç±»å‹åˆ†ç»„)
# python run_cortex_workflow.py
# python run_improved_cortex_workflow.py  # å¯é€‰ï¼šæ”¹è¿›ç‰ˆ
# python run_enhanced_cortex_workflow.py  # å¯é€‰ï¼šå¢å¼ºç‰ˆ

# 4. å…³ç³»åˆ†æï¼ˆçœŸæ­£çš„å…³ç³»æŠ½å–ï¼Œåœ¨èšç±»å®Œæˆåè¿›è¡Œï¼‰
python run_relationship_analysis.py

# 5. å­¦ä¹ å·¥ä½œæµ
python run_learning_workflow.py
```

**âš ï¸ èšç±»æ–¹æ³•é€‰æ‹©è¯´æ˜ï¼š**
- **æ™ºèƒ½èšç±»** (`run_smart_clustering.py`) - Aç»„ä»¶çš„æ ¸å¿ƒæ”¹è¿›ï¼Œæ¨èä½¿ç”¨
- **Cortexèšç±»** (`run_cortex_workflow.py`) - åŸºäºäº‹ä»¶ç±»å‹çš„ç®€å•åˆ†ç»„
- **äºŒé€‰ä¸€å³å¯**ï¼Œä¸éœ€è¦åŒæ—¶è¿è¡Œå¤šç§èšç±»æ–¹æ³•
- **å…³ç³»åˆ†æ** (`run_relationship_analysis.py`) æ˜¯ç‹¬ç«‹çš„å…³ç³»æŠ½å–æ­¥éª¤

#### æµç¨‹3: è´¨é‡è¯„ä¼° (Cç»„ä»¶)

```bash
# 1. èšç±»è´¨é‡è¯„ä¼°
python run_clustering_evaluation.py \
  --group-by story_id \
  --status pending_relationship_analysis \
  --sample-per-group 3 \
  --out-dir outputs

# 2. æŸ¥çœ‹è¯„ä¼°ç»“æœ
cat outputs/clustering_evaluation_report_*.json

# 3. äººå·¥è´¨é‡æ£€æŸ¥
# ç”¨Excelæˆ–æ–‡æœ¬ç¼–è¾‘å™¨æ‰“å¼€: outputs/clustering_evaluation_samples_*.csv
```

#### æµç¨‹4: æœåŠ¡éƒ¨ç½²

```bash
# 1. å¯åŠ¨APIæœåŠ¡ (Bç»„ä»¶)
python enhanced_api.py &

# 2. å¯åŠ¨å‰ç«¯ (å¯é€‰)
cd frontend && npm run dev &

# 3. WebSocketæ”¯æŒ
python start_api_with_websocket.py &

# 4. æµ‹è¯•è¿æ¥
curl http://localhost:8080/api/status
curl http://localhost:8080/api/events?limit=5
```

### ğŸ› ï¸ é«˜çº§é…ç½®

#### å¹¶è¡Œå¤„ç†ä¼˜åŒ–

```bash
# å¤šè¿›ç¨‹èšç±» (æœ‰å¤šæ ¸å¿ƒæ—¶)
python run_smart_clustering.py --mode company --max_story_size 15 &
python run_smart_clustering.py --mode theme --max_story_size 20 &
wait

# æ‰¹é‡å¤„ç†ä¼˜åŒ–
python run_batch_triage.py --batch_size 100 --parallel 4
```

#### æ¨¡å‹é…ç½®è°ƒæ•´

ç¼–è¾‘ `model_config.yaml`:
```yaml
llm_config:
  model: "gpt-4"  # æˆ–å…¶ä»–æ¨¡å‹
  temperature: 0.1
  max_tokens: 4000

clustering_config:
  company_threshold: 0.7
  theme_threshold: 0.6
  max_iterations: 10
```

#### æ•°æ®åº“ä¼˜åŒ–

```bash
# æ•°æ®åº“ç»´æŠ¤
python diagnose_database.py
python check_table_structure.py

# å¤‡ä»½ä¸æ¢å¤
cp master_state.db master_state_backup.db
python restore_database.py master_state_backup.db  # å¦‚éœ€æ¢å¤
```

### ğŸ› æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

**1. å¯¼å…¥æ•°æ®ä¸º0æ¡**
```bash
# æ£€æŸ¥æ–‡ä»¶æ ¼å¼
head -2 test_import_20.jsonl
# ç¡®ä¿JSONæ ¼å¼æ­£ç¡®ï¼Œé‡æ–°å¯¼å…¥
python simple_import.py test_import_20.jsonl
```

**2. èšç±»å¤±è´¥**
```bash
# æ£€æŸ¥çŠ¶æ€
python check_database_status.py
# ç¡®ä¿æœ‰ pending_clustering çŠ¶æ€çš„è®°å½•
# æ£€æŸ¥é…ç½®æ–‡ä»¶
cat config.yaml
```

**3. APIæœåŠ¡æ— æ³•å¯åŠ¨**
```bash
# æ£€æŸ¥ç«¯å£å ç”¨
netstat -tlnp | grep 8080
# æ›´æ”¹ç«¯å£æˆ–åœæ­¢å†²çªæœåŠ¡
python enhanced_api.py --port 8081
```

**4. è¯„ä¼°è„šæœ¬numpyé”™è¯¯**
```bash
# æ›´æ–°ä¾èµ–
pip install --upgrade scikit-learn pandas numpy
# æˆ–ä½¿ç”¨condaç¯å¢ƒ
conda update scikit-learn pandas numpy
```

**5. å†…å­˜ä¸è¶³**
```bash
# å‡å°‘batch_size
python run_batch_triage.py --batch_size 25
# æˆ–åˆ†æ‰¹å¤„ç†å¤§æ•°æ®é›†
```

### ğŸ“ˆ æ€§èƒ½ç›‘æ§

#### æ€§èƒ½æŒ‡æ ‡ç›‘æ§

```bash
# å¤„ç†é€Ÿåº¦ç›‘æ§
python -c "
import time, sqlite3
con = sqlite3.connect('master_state.db')
cur = con.cursor()
count = cur.execute('SELECT COUNT(*) FROM master_state').fetchone()[0]
print(f'å½“å‰è®°å½•æ•°: {count}')
con.close()
"

# ç³»ç»Ÿèµ„æºç›‘æ§
htop  # æˆ– top æŸ¥çœ‹CPU/å†…å­˜ä½¿ç”¨
df -h  # æŸ¥çœ‹ç£ç›˜ç©ºé—´
```

#### æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **å°æ•°æ®é›† (<1000äº‹ä»¶)**: ä½¿ç”¨é»˜è®¤é…ç½®
2. **ä¸­æ•°æ®é›† (1K-10Käº‹ä»¶)**: å¢åŠ batch_sizeåˆ°100
3. **å¤§æ•°æ®é›† (>10Käº‹ä»¶)**: 
   - ä½¿ç”¨å¹¶è¡Œå¤„ç†
   - åˆ†æ‰¹å¯¼å…¥å’Œå¤„ç†
   - è€ƒè™‘ä½¿ç”¨æ›´å¼ºå¤§çš„æœåŠ¡å™¨

### ğŸ¯ æœ€ä½³å®è·µ

#### æ•°æ®è´¨é‡
- å®šæœŸè¿è¡Œ `check_data_integrity.py`
- ä½¿ç”¨è¯„ä¼°ç»„ä»¶ç›‘æ§èšç±»è´¨é‡
- å®šæœŸå¤‡ä»½æ•°æ®åº“

#### å¼€å‘æµç¨‹
- å…ˆç”¨å°æ•°æ®é›†æµ‹è¯• (`test_import_20.jsonl`)
- éªŒè¯å„ç»„ä»¶æ­£å¸¸åå†å¤„ç†å¤§æ•°æ®é›†
- ä½¿ç”¨è¯„ä¼°æŠ¥å‘Šä¼˜åŒ–èšç±»å‚æ•°

#### ç”Ÿäº§éƒ¨ç½²
- é…ç½®é€‚å½“çš„æ—¥å¿—çº§åˆ«
- è®¾ç½®ç›‘æ§å‘Šè­¦
- å®šæœŸæ›´æ–°ä¾èµ–åŒ…
- ä½¿ç”¨è´Ÿè½½å‡è¡¡ï¼ˆå¦‚æœ‰å¤šå®ä¾‹ï¼‰

## ğŸ“ æ”¯æŒä¸ç»´æŠ¤

å¦‚éœ€æŠ€æœ¯æ”¯æŒï¼Œå¯ä»¥ï¼š
1. æŸ¥çœ‹å„ç»„ä»¶çš„è¯¦ç»†æ–‡æ¡£ (`docs/` ç›®å½•)
2. è¿è¡Œè¯Šæ–­è„šæœ¬æ’æŸ¥é—®é¢˜
3. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
4. å‚è€ƒæœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†

ç³»ç»Ÿä¼šæŒç»­æ›´æ–°å’Œä¼˜åŒ–ï¼Œå»ºè®®å®šæœŸæ£€æŸ¥æ›´æ–°ã€‚
