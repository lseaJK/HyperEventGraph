#!/usr/bin/env python3
"""
Simplified FastAPI backend for HyperEventGraph web interface.
This version uses minimal dependencies for quick testing.
"""

import sqlite3
import sys
import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional
import subprocess
import signal
import threading

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

app = FastAPI(
    title="HyperEventGraph API",
    description="API for managing and visualizing the HyperEventGraph system.",
    version="0.1.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
project_root = Path(__file__).resolve().parent
DB_PATH = project_root / "master_state.db"

WORKFLOW_SCRIPTS = {
    "triage": "run_batch_triage.py",
    "extraction": "run_extraction_workflow.py", 
    "learning": "run_learning_workflow.py",
    "cortex": "run_cortex_workflow.py",
    "relationship_analysis": "run_relationship_analysis.py",
}

# WebSocketè¿æ¥ç®¡ç†
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[int, WebSocket] = {}
        self.counter = 0

    async def connect(self, websocket: WebSocket) -> int:
        """æ¥å—WebSocketè¿æ¥"""
        await websocket.accept()
        self.counter += 1
        connection_id = self.counter
        self.active_connections[connection_id] = websocket
        return connection_id

    def disconnect(self, connection_id: int):
        """æ–­å¼€è¿æ¥"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]

    async def send_personal_message(self, message: str, connection_id: int):
        """å‘é€ä¸ªäººæ¶ˆæ¯"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            try:
                await websocket.send_text(message)
            except:
                self.disconnect(connection_id)

    async def broadcast(self, message: str):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥"""
        disconnected = []
        for connection_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(message)
            except:
                disconnected.append(connection_id)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for connection_id in disconnected:
            self.disconnect(connection_id)

# å·¥ä½œæµè¿›ç¨‹ç®¡ç†
class WorkflowProcessManager:
    def __init__(self):
        self.running_processes: Dict[str, subprocess.Popen] = {}
        self.workflow_threads: Dict[str, threading.Thread] = {}
        self.stop_flags: Dict[str, bool] = {}
    
    def start_process(self, workflow_name: str, script_path: str, params: Dict = None) -> bool:
        """å¯åŠ¨å·¥ä½œæµè¿›ç¨‹"""
        if workflow_name in self.running_processes:
            return False
        
        try:
            cmd = ["python", script_path]
            if params:
                # å°†å‚æ•°è½¬æ¢ä¸ºå‘½ä»¤è¡Œå‚æ•°ï¼ˆæ ¹æ®å…·ä½“è„šæœ¬æ”¯æŒçš„å‚æ•°æ ¼å¼ï¼‰
                for key, value in params.items():
                    if value is not None:
                        cmd.extend([f"--{key}", str(value)])
            
            # å¯åŠ¨è¿›ç¨‹
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            self.running_processes[workflow_name] = process
            self.stop_flags[workflow_name] = False
            
            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­ç›‘æ§è¿›ç¨‹è¾“å‡º
            thread = threading.Thread(
                target=self._monitor_process,
                args=(workflow_name, process)
            )
            thread.daemon = True
            thread.start()
            
            self.workflow_threads[workflow_name] = thread
            return True
            
        except Exception as e:
            print(f"Failed to start workflow {workflow_name}: {e}")
            return False
    
    def stop_process(self, workflow_name: str) -> bool:
        """åœæ­¢å·¥ä½œæµè¿›ç¨‹"""
        if workflow_name not in self.running_processes:
            return False
        
        try:
            process = self.running_processes[workflow_name]
            self.stop_flags[workflow_name] = True
            
            # ä¼˜é›…åœæ­¢
            if process.poll() is None:
                process.terminate()
                
                # ç­‰å¾…5ç§’ï¼Œå¦‚æœè¿˜æ²¡åœæ­¢å°±å¼ºåˆ¶æ€æ­»
                try:
                    process.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    process.kill()
                    process.wait()
            
            # æ¸…ç†
            del self.running_processes[workflow_name]
            if workflow_name in self.workflow_threads:
                del self.workflow_threads[workflow_name]
            if workflow_name in self.stop_flags:
                del self.stop_flags[workflow_name]
                
            return True
            
        except Exception as e:
            print(f"Failed to stop workflow {workflow_name}: {e}")
            return False
    
    def get_process_status(self, workflow_name: str) -> str:
        """è·å–è¿›ç¨‹çŠ¶æ€"""
        if workflow_name not in self.running_processes:
            return "Idle"
        
        process = self.running_processes[workflow_name]
        if process.poll() is None:
            return "Running"
        else:
            return "Completed"
    
    def is_running(self, workflow_name: str) -> bool:
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return (workflow_name in self.running_processes and 
                self.running_processes[workflow_name].poll() is None)
    
    def _monitor_process(self, workflow_name: str, process: subprocess.Popen):
        """ç›‘æ§è¿›ç¨‹è¾“å‡ºå¹¶é€šè¿‡WebSocketå¹¿æ’­"""
        import time
        
        async def broadcast_message(message: str):
            """å¼‚æ­¥å¹¿æ’­æ¶ˆæ¯çš„åŒ…è£…å‡½æ•°"""
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                await manager.broadcast(message)
                loop.close()
            except Exception as e:
                print(f"WebSocket broadcast failed: {e}")
        
        def sync_broadcast(message: str):
            """åŒæ­¥ç‰ˆæœ¬çš„å¹¿æ’­"""
            try:
                asyncio.run(broadcast_message(message))
            except Exception as e:
                print(f"Sync broadcast failed: {e}")
        
        try:
            sync_broadcast(f"ğŸš€ [{workflow_name}] å·¥ä½œæµå·²å¯åŠ¨")
            
            while process.poll() is None and not self.stop_flags.get(workflow_name, False):
                # è¯»å–æ ‡å‡†è¾“å‡º
                if process.stdout:
                    try:
                        output = process.stdout.readline()
                        if output:
                            sync_broadcast(f"ğŸ“Š [{workflow_name}] {output.strip()}")
                    except Exception:
                        pass
                
                # è¯»å–é”™è¯¯è¾“å‡º
                if process.stderr:
                    try:
                        error = process.stderr.readline()
                        if error:
                            sync_broadcast(f"âš ï¸ [{workflow_name}] {error.strip()}")
                    except Exception:
                        pass
                
                time.sleep(0.1)  # é¿å…è¿‡åº¦å ç”¨CPU
            
            # è¿›ç¨‹ç»“æŸåçš„çŠ¶æ€æ£€æŸ¥
            return_code = process.wait()
            if return_code == 0:
                sync_broadcast(f"âœ… [{workflow_name}] å·¥ä½œæµå®Œæˆ")
            else:
                sync_broadcast(f"âŒ [{workflow_name}] å·¥ä½œæµå¤±è´¥ (è¿”å›ç : {return_code})")
                
                # è¯»å–å‰©ä½™çš„é”™è¯¯è¾“å‡º
                if process.stderr:
                    remaining_errors = process.stderr.read()
                    if remaining_errors:
                        sync_broadcast(f"âŒ [{workflow_name}] é”™è¯¯è¯¦æƒ…: {remaining_errors}")
            
        except Exception as e:
            sync_broadcast(f"âŒ [{workflow_name}] ç›‘æ§è¿›ç¨‹å¼‚å¸¸: {str(e)}")
        finally:
            # æ¸…ç†
            if workflow_name in self.running_processes:
                del self.running_processes[workflow_name]
            if workflow_name in self.workflow_threads:
                del self.workflow_threads[workflow_name]
            if workflow_name in self.stop_flags:
                del self.stop_flags[workflow_name]
# WebSocketè¿æ¥ç®¡ç†
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[int, WebSocket] = {}
        self.counter = 0

    async def connect(self, websocket: WebSocket) -> int:
        """æ¥å—WebSocketè¿æ¥"""
        await websocket.accept()
        self.counter += 1
        connection_id = self.counter
        self.active_connections[connection_id] = websocket
        return connection_id

    def disconnect(self, connection_id: int):
        """æ–­å¼€è¿æ¥"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]

    async def send_personal_message(self, message: str, connection_id: int):
        """å‘é€ä¸ªäººæ¶ˆæ¯"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            try:
                await websocket.send_text(message)
            except:
                self.disconnect(connection_id)

    async def broadcast(self, message: str):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥"""
        disconnected = []
        for connection_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(message)
            except:
                disconnected.append(connection_id)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for connection_id in disconnected:
            self.disconnect(connection_id)
        disconnected_ids = []
        for connection_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(message)
            except Exception as e:
                print(f"Error sending message to client {connection_id}: {e}")
                disconnected_ids.append(connection_id)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for id in disconnected_ids:
            self.disconnect(id)

    async def send_to_client(self, client_id: int, message: str):
        if client_id in self.active_connections:
            try:
                await self.active_connections[client_id].send_text(message)
            except Exception as e:
                print(f"Error sending message to client {client_id}: {e}")
                self.disconnect(client_id)

# åˆ›å»ºè¿æ¥ç®¡ç†å™¨å®ä¾‹
manager = ConnectionManager()
process_manager = WorkflowProcessManager()

# æ¨¡æ‹Ÿå·¥ä½œæµçŠ¶æ€
workflow_status = {name: {"status": "Idle", "last_run": None} for name in WORKFLOW_SCRIPTS}

def get_status_summary() -> Dict[str, int]:
    """Get status summary from database."""
    if not DB_PATH.exists():
        return {"pending_triage": 0, "pending_extraction": 0, "completed": 0}
    
    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        cursor.execute("SELECT current_status, COUNT(*) FROM master_state GROUP BY current_status")
        results = cursor.fetchall()
        conn.close()
        
        status_dict = {status: count for status, count in results}
        return status_dict
        
    except Exception as e:
        print(f"Database error: {e}")
        return {"error": "Database unavailable"}

@app.get("/")
async def read_root():
    """Root endpoint to check if the API is running."""
    return {"message": "HyperEventGraph API is running", "status": "ok"}

# Pydanticæ¨¡å‹å®šä¹‰
class WorkflowParams(BaseModel):
    batch_size: int = None
    extraction_mode: str = None
    learning_mode: str = None
    confidence_threshold: float = None
    clustering_threshold: float = None
    analysis_depth: str = None
    min_cluster_size: int = None
    dbscan_eps: float = None

# ç»Ÿä¸€çš„å·¥ä½œæµå¯åŠ¨å‡½æ•°
async def start_workflow_internal(workflow_name: str, params: WorkflowParams = None, background_tasks: BackgroundTasks = None):
    """Internal function to start a workflow."""
    if workflow_name not in WORKFLOW_SCRIPTS:
        raise HTTPException(status_code=404, detail=f"Workflow '{workflow_name}' not found.")
    
    if process_manager.is_running(workflow_name):
        raise HTTPException(status_code=400, detail=f"Workflow '{workflow_name}' is already running.")
    
    # è·å–è„šæœ¬è·¯å¾„
    script_path = WORKFLOW_SCRIPTS[workflow_name]
    
    # å‡†å¤‡å‚æ•°
    workflow_params = params.dict(exclude_none=True) if params else {}
    
    # åœ¨æ§åˆ¶å°æ‰“å°å‚æ•°ï¼Œä¾¿äºè°ƒè¯•
    if workflow_params:
        print(f"Starting {workflow_name} with params: {workflow_params}")
    
    # ä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨å¯åŠ¨å·¥ä½œæµ
    success = process_manager.start_process(workflow_name, script_path, workflow_params)
    
    if success:
        # æ›´æ–°çŠ¶æ€
        workflow_status[workflow_name]["status"] = "Running"
        workflow_status[workflow_name]["last_run"] = datetime.now().isoformat()
        
        await manager.broadcast(f"ğŸš€ å·¥ä½œæµ '{workflow_name}' å·²å¯åŠ¨")
        
        return {
            "message": f"Workflow '{workflow_name}' started successfully.",
            "status": "started",
            "workflow": workflow_name,
            "params": workflow_params
        }
    else:
        raise HTTPException(status_code=500, detail=f"Failed to start workflow '{workflow_name}'.")

# ä¿ç•™åŸæ¥çš„æ¨¡æ‹Ÿå·¥ä½œæµå‡½æ•°ä½œä¸ºå¤‡ç”¨
async def simulate_workflow_legacy(workflow_name: str, params: WorkflowParams = None):
    
    return {
        "message": f"Workflow '{workflow_name}' start requested.",
        "status": "accepted",
        "workflow": workflow_name,
        "params": params.dict(exclude_none=True) if params else {}
    }

# WebSocketç«¯ç‚¹
@app.websocket("/ws/{client_id}")
async def websocket_endpoint(websocket: WebSocket, client_id: int):
    """WebSocketç«¯ç‚¹ï¼Œç”¨äºå®æ—¶æ—¥å¿—"""
    connection_id = await manager.connect(websocket)
    await websocket.send_text(f"> å·²è¿æ¥åˆ°WebSocketï¼ŒID: {connection_id}")
    
    try:
        while True:
            # ä¿æŒè¿æ¥æ´»è·ƒ
            data = await websocket.receive_text()
            # å¦‚æœå®¢æˆ·ç«¯å‘é€äº†æ¶ˆæ¯ï¼Œå¯ä»¥åœ¨è¿™é‡Œå¤„ç†
    except WebSocketDisconnect:
        manager.disconnect(connection_id)
        print(f"å®¢æˆ·ç«¯ #{connection_id} æ–­å¼€è¿æ¥")

# æ¨¡æ‹Ÿå·¥ä½œæµæ‰§è¡Œ
async def simulate_workflow(workflow_name: str, params=None):
    """æ¨¡æ‹Ÿå·¥ä½œæµæ‰§è¡Œï¼Œå¹¶é€šè¿‡WebSocketå‘é€è¿›åº¦"""
    if workflow_name not in WORKFLOW_SCRIPTS:
        return
    
    # æ›´æ–°çŠ¶æ€
    workflow_status[workflow_name]["status"] = "Running"
    workflow_status[workflow_name]["last_run"] = datetime.now().isoformat()
    
    # å‘é€å¯åŠ¨æ¶ˆæ¯
    await manager.broadcast(f"> {workflow_name}: å·¥ä½œæµå¼€å§‹æ‰§è¡Œ")
    
    # å¦‚æœæœ‰å‚æ•°ï¼Œæ˜¾ç¤ºå‚æ•°ä¿¡æ¯
    if params:
        param_dict = params.dict(exclude_none=True)
        if param_dict:
            param_str = ", ".join([f"{k}={v}" for k, v in param_dict.items()])
            await manager.broadcast(f"> {workflow_name}: ä½¿ç”¨å‚æ•° {param_str}")
    
    # æ ¹æ®ä¸åŒå·¥ä½œæµç±»å‹ï¼Œæ¨¡æ‹Ÿä¸“æœ‰çš„æ‰§è¡Œé˜¶æ®µ
    if workflow_name == "extraction":
        stages = [
            "åŠ è½½äº‹ä»¶æ¨¡å¼...",
            "å‡†å¤‡æŠ½å–æ¨¡å‹...",
            "æ‰¹é‡å¤„ç†æ–‡æœ¬...",
            "æ‰§è¡Œç»“æ„åŒ–æŠ½å–...",
            "éªŒè¯æŠ½å–ç»“æœ..."
        ]
    elif workflow_name == "learning":
        stages = [
            "åŠ è½½æœªçŸ¥äº‹ä»¶æ ·æœ¬...",
            "æ‰§è¡Œäº‹ä»¶èšç±»åˆ†æ...",
            "ç”Ÿæˆäº‹ä»¶æ¨¡å¼å€™é€‰...",
            "éªŒè¯æ–°äº‹ä»¶æ¨¡å¼..."
        ]
    elif workflow_name == "triage":
        stages = [
            "åŠ è½½æ–‡æœ¬æ•°æ®...",
            "æ‰§è¡Œåˆæ­¥åˆ†ç±»...",
            "è¿‡æ»¤ä½ç½®ä¿¡åº¦ç»“æœ...",
            "å‡†å¤‡äººå·¥å®¡æ ¸å†…å®¹..."
        ]
    elif workflow_name == "cortex":
        stages = [
            "åˆå§‹åŒ–Cortexå¼•æ“...",
            "åŠ è½½äº‹ä»¶å‘é‡åŒ–æ¨¡å‹...",
            "æ‰§è¡Œèšç±»ç®—æ³•...",
            "ç²¾ç‚¼äº‹ä»¶ç°‡...",
            "ç”Ÿæˆæ•…äº‹å•å…ƒ..."
        ]
    elif workflow_name == "relationship_analysis":
        stages = [
            "åŠ è½½å·²æŠ½å–äº‹ä»¶...",
            "åˆå§‹åŒ–å…³ç³»åˆ†ææ¨¡å‹...",
            "è¯†åˆ«äº‹ä»¶é—´å› æœå…³ç³»...",
            "æ„å»ºçŸ¥è¯†å›¾è°±...",
            "æ›´æ–°å­˜å‚¨åº“..."
        ]
    else:
        stages = [
            "åŠ è½½é…ç½®...",
            "å‡†å¤‡æ•°æ®...",
            "å¤„ç†ä¸­...",
            "å®Œæˆä»»åŠ¡"
        ]
    
    for stage in stages:
        await asyncio.sleep(1.5)  # æ¨¡æ‹Ÿæ¯ä¸ªé˜¶æ®µçš„æ‰§è¡Œæ—¶é—´
        await manager.broadcast(f"> {workflow_name}: {stage}")
    
    # æ¨¡æ‹Ÿå®Œæˆ
    workflow_status[workflow_name]["status"] = "Completed"
    await manager.broadcast(f"> {workflow_name}: å·¥ä½œæµå®Œæˆï¼ŒçŠ¶æ€ç  0")

# å°†APIç«¯ç‚¹è°ƒæ•´ä¸ºä¸enhanced_api.pyä¸€è‡´çš„è·¯å¾„
@app.get("/api/status")
async def get_api_status():
    """è·å–ç³»ç»ŸçŠ¶æ€æ‘˜è¦"""
    return get_status_summary()

@app.get("/api/workflows")
async def get_api_workflows():
    """è·å–å¯ç”¨å·¥ä½œæµ"""
    workflows = []
    for name, info in workflow_status.items():
        workflows.append({
            "name": name,
            "status": info["status"],
            "last_run": info["last_run"],
        })
    return workflows

@app.get("/api/events")
async def get_events(page: int = 0, page_size: int = 10):
    """è·å–äº‹ä»¶æ•°æ® - åˆ†é¡µ (å·²ä¿®å¤ï¼ŒæŸ¥è¯¢æ­£ç¡®çš„æ•°æ®è¡¨)"""
    conn = None
    try:
        import sqlite3
        import json
        conn = sqlite3.connect("master_state.db")
        conn.row_factory = sqlite3.Row  # å…è®¸æŒ‰åˆ—åè®¿é—®æ•°æ®

        cursor = conn.cursor()

        # é¦–å…ˆï¼Œä»æ­£ç¡®çš„ç›®æ ‡è¡¨ event_data ä¸­è·å–æ€»è¡Œæ•°
        cursor.execute("SELECT COUNT(*) FROM event_data WHERE processed = 1")
        total_count = cursor.fetchone()[0]

        # ç„¶åï¼Œè·å–åˆ†é¡µåçš„è¯¦ç»†æ•°æ®
        offset = page * page_size
        cursor.execute("""
            SELECT id, event_type, trigger, entities, summary 
            FROM event_data 
            WHERE processed = 1
            ORDER BY id DESC
            LIMIT ? OFFSET ?
        """, (page_size, offset))
        
        rows = cursor.fetchall()
        
        # å°†æ•°æ®åº“è¡Œæ ¼å¼åŒ–ä¸ºå‰ç«¯æœŸæœ›çš„JSONå¯¹è±¡
        events = []
        for row in rows:
            try:
                # 'entities' å­—æ®µåœ¨æ•°æ®åº“ä¸­æ˜¯JSONå­—ç¬¦ä¸²ï¼Œéœ€è¦è§£ææˆæ•°ç»„
                entities_list = json.loads(row['entities']) if row['entities'] else []
            except (json.JSONDecodeError, TypeError):
                entities_list = []

            events.append({
                "id": row['id'],
                "event_type": row['event_type'],
                "trigger": row['trigger'],
                "involved_entities": entities_list,
                "event_summary": row['summary'],
            })
        
        return {
            "events": events,
            "pagination": {
                "page": page,
                "page_size": page_size,
                "total": total_count,
                "pages": (total_count + page_size - 1) // page_size
            }
        }
        
    except Exception as e:
        print(f"è·å–äº‹ä»¶æ•°æ®æ—¶å‡ºé”™: {e}")
        # å¦‚æœå‡ºé”™ï¼Œè¿”å›ä¸€ä¸ªç»“æ„å®Œæ•´çš„ç©ºå“åº”
        return {
            "events": [],
            "pagination": { "page": page, "page_size": page_size, "total": 0, "pages": 0 }
        }
    finally:
        if conn:
            conn.close()

@app.get("/api/graph")
async def get_graph_data():
    """è·å–çŸ¥è¯†å›¾è°±æ•°æ® - ä¸ºå‰ç«¯æä¾›æ ‡å‡†åŒ–æ•°æ®æ ¼å¼"""
    nodes = []
    edges = []
    conn = None
    try:
        import sqlite3
        conn = sqlite3.connect("master_state.db")
        cursor = conn.cursor()
        
        # ä¼˜å…ˆè·å–å·²å¤„ç†çš„äº‹ä»¶æ•°æ®
        cursor.execute("""
            SELECT id, source_text, current_status, assigned_event_type, notes
            FROM master_state 
            WHERE current_status IN ('triaged', 'extracted', 'clustered', 'analyzed')
            LIMIT 50
        """)
        rows = cursor.fetchall()
        
        # å¦‚æœæ²¡æœ‰å¤„ç†è¿‡çš„æ•°æ®ï¼Œåˆ™ä»æ‰€æœ‰æ•°æ®ä¸­å–æ ·æœ¬ä½œä¸ºå¤‡ç”¨
        if not rows:
            cursor.execute("""
                SELECT id, source_text, current_status, assigned_event_type, notes
                FROM master_state 
                LIMIT 20
            """)
            rows = cursor.fetchall()

        # æ„å»ºèŠ‚ç‚¹å’Œè¾¹
        for i, row in enumerate(rows):
            event_id, source_text, status, event_type, notes = row
            
            # åˆ›å»ºäº‹ä»¶èŠ‚ç‚¹
            nodes.append({
                "id": event_id,
                "type": "Event",
                "name": f"{event_type or 'Event'}_{event_id[:8]}",
                "level": "mid" if status in ('triaged', 'extracted', 'clustered', 'analyzed') else "low",
                "summary": source_text[:100] + "..." if len(source_text) > 100 else source_text
            })
            
            # å¦‚æœæœ‰äº‹ä»¶ç±»å‹ï¼Œåˆ›å»ºç±»å‹èŠ‚ç‚¹
            if event_type:
                type_id = f"type_{event_type}"
                if not any(n["id"] == type_id for n in nodes):
                    nodes.append({
                        "id": type_id,
                        "type": "EventCategory", 
                        "name": event_type,
                        "level": "high"
                    })
                
                # è¿æ¥äº‹ä»¶åˆ°ç±»å‹
                edges.append({
                    "source": event_id,
                    "target": type_id,
                    "label": "BELONGS_TO"
                })
        
        return {"nodes": nodes, "links": edges}
        
    except Exception as e:
        print(f"è·å–å›¾è°±æ•°æ®æ—¶å‡ºé”™: {e}")
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›ç©ºçš„å›¾è°±ç»“æ„ï¼Œé¿å…å‰ç«¯å´©æºƒ
        return {"nodes": [], "links": []}
    finally:
        if conn:
            conn.close()

@app.post("/api/workflow/{workflow_name}/start")
async def start_api_workflow(workflow_name: str, params: WorkflowParams = None, background_tasks: BackgroundTasks = None):
    """å¯åŠ¨å·¥ä½œæµ - APIç‰ˆæœ¬"""
    return await start_workflow_internal(workflow_name, params, background_tasks)

@app.post("/api/workflow/{workflow_name}/stop")
async def stop_workflow(workflow_name: str):
    """åœæ­¢å·¥ä½œæµ"""
    if workflow_name not in WORKFLOW_SCRIPTS:
        raise HTTPException(status_code=404, detail=f"Workflow '{workflow_name}' not found.")
    
    # ä½¿ç”¨è¿›ç¨‹ç®¡ç†å™¨åœæ­¢å·¥ä½œæµ
    success = process_manager.stop_process(workflow_name)
    
    if success:
        # æ›´æ–°çŠ¶æ€
        workflow_status[workflow_name]["status"] = "Idle"
        await manager.broadcast(f"â¹ï¸ å·¥ä½œæµ '{workflow_name}' å·²åœæ­¢")
        
        return {
            "message": f"Workflow '{workflow_name}' stopped successfully.",
            "status": "stopped",
            "workflow": workflow_name
        }
    else:
        raise HTTPException(status_code=400, detail=f"Failed to stop workflow '{workflow_name}' or it's not running.")

@app.get("/api/workflow/{workflow_name}/status")
async def get_workflow_status(workflow_name: str):
    """è·å–ç‰¹å®šå·¥ä½œæµçš„è¯¦ç»†çŠ¶æ€"""
    if workflow_name not in WORKFLOW_SCRIPTS:
        raise HTTPException(status_code=404, detail=f"Workflow '{workflow_name}' not found.")
    
    process_status = process_manager.get_process_status(workflow_name)
    is_running = process_manager.is_running(workflow_name)
    
    return {
        "name": workflow_name,
        "status": process_status,
        "is_running": is_running,
        "last_run": workflow_status[workflow_name]["last_run"],
        "can_stop": is_running,
        "can_start": not is_running
    }

# æ•°æ®å¯¼å…¥API
class ImportDataRequest(BaseModel):
    dataFile: str

@app.post("/api/import-data")
async def import_data(request: ImportDataRequest):
    """å¯¼å…¥æ•°æ®åˆ°ç³»ç»Ÿ"""
    try:
        await manager.broadcast(f"ğŸ”„ å¼€å§‹å¯¼å…¥æ•°æ®: {request.dataFile}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        file_path = Path(request.dataFile)
        if not file_path.exists():
            error_msg = f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {request.dataFile}"
            await manager.broadcast(f"âŒ {error_msg}")
            raise HTTPException(status_code=404, detail=error_msg)
        
        # æ‰§è¡Œå¯¼å…¥è„šæœ¬
        import_cmd = ["python", "import_text_array.py", str(file_path)]
        process = subprocess.run(
            import_cmd,
            capture_output=True,
            text=True,
            cwd=project_root
        )
        
        if process.returncode == 0:
            await manager.broadcast(f"âœ… æ•°æ®å¯¼å…¥å®Œæˆ: {request.dataFile}")
            await manager.broadcast(f"ğŸ“Š å¯¼å…¥è¾“å‡º: {process.stdout}")
            return {
                "message": "æ•°æ®å¯¼å…¥æˆåŠŸ",
                "file": request.dataFile,
                "output": process.stdout
            }
        else:
            error_msg = f"æ•°æ®å¯¼å…¥å¤±è´¥: {process.stderr}"
            await manager.broadcast(f"âŒ {error_msg}")
            raise HTTPException(status_code=500, detail=error_msg)
            
    except Exception as e:
        error_msg = f"å¯¼å…¥è¿‡ç¨‹å‡ºé”™: {str(e)}"
        await manager.broadcast(f"âŒ {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

# å®Œæ•´æµç¨‹API
class FullPipelineRequest(BaseModel):
    includeImport: bool = True
    dataFile: str = "IC_data/filtered_data.json"
    concurrency: int = 3

@app.post("/api/run-full-pipeline")
async def run_full_pipeline(request: FullPipelineRequest, background_tasks: BackgroundTasks):
    """æ‰§è¡Œå®Œæ•´çš„æ•°æ®å¤„ç†æµç¨‹"""
    try:
        await manager.broadcast("ğŸš€ å¼€å§‹æ‰§è¡Œå®Œæ•´æµç¨‹")
        
        pipeline_steps = [
            "æ•°æ®å¯¼å…¥",
            "äº‹ä»¶åˆ†ç±»", 
            "äº‹ä»¶æå–",
            "äº‹ä»¶èšç±»",
            "å…³ç³»åˆ†æ",
            "çŸ¥è¯†å›¾è°±æ„å»º"
        ]
        
        # å¦‚æœåŒ…å«å¯¼å…¥æ­¥éª¤
        if request.includeImport:
            await manager.broadcast(f"ğŸ“‚ æ­¥éª¤ 1/6: å¼€å§‹æ•°æ®å¯¼å…¥ - {request.dataFile}")
            
            # æ‰§è¡Œæ•°æ®å¯¼å…¥
            file_path = Path(request.dataFile)
            if not file_path.exists():
                error_msg = f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {request.dataFile}"
                await manager.broadcast(f"âŒ {error_msg}")
                raise HTTPException(status_code=404, detail=error_msg)
            
            import_cmd = ["python", "import_text_array.py", str(file_path)]
            import_process = subprocess.run(
                import_cmd,
                capture_output=True,
                text=True,
                cwd=project_root
            )
            
            if import_process.returncode == 0:
                await manager.broadcast("âœ… æ­¥éª¤ 1/6: æ•°æ®å¯¼å…¥å®Œæˆ")
            else:
                error_msg = f"æ•°æ®å¯¼å…¥å¤±è´¥: {import_process.stderr}"
                await manager.broadcast(f"âŒ {error_msg}")
                raise HTTPException(status_code=500, detail=error_msg)
        
        # æ‰§è¡Œåç»­æ­¥éª¤
        step_scripts = [
            ("run_batch_triage.py", "äº‹ä»¶åˆ†ç±»"),
            ("run_extraction_workflow.py", "äº‹ä»¶æå–"),
            ("run_cortex_workflow.py", "äº‹ä»¶èšç±»"),
            ("run_relationship_analysis.py", "å…³ç³»åˆ†æ")
        ]
        
        current_step = 2 if request.includeImport else 1
        
        for script_name, step_name in step_scripts:
            await manager.broadcast(f"ğŸ”„ æ­¥éª¤ {current_step}/6: å¼€å§‹{step_name}")
            
            # æ£€æŸ¥è„šæœ¬æ˜¯å¦å­˜åœ¨
            script_path = project_root / script_name
            if not script_path.exists():
                await manager.broadcast(f"âš ï¸ è·³è¿‡æ­¥éª¤ {current_step}/6: {script_name} ä¸å­˜åœ¨")
                current_step += 1
                continue
            
            # æ‰§è¡Œè„šæœ¬
            cmd = ["python", script_name]
            if step_name == "äº‹ä»¶æå–" and request.concurrency:
                cmd.extend(["--concurrency", str(request.concurrency)])
            
            step_process = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                cwd=project_root
            )
            
            if step_process.returncode == 0:
                await manager.broadcast(f"âœ… æ­¥éª¤ {current_step}/6: {step_name}å®Œæˆ")
            else:
                await manager.broadcast(f"âš ï¸ æ­¥éª¤ {current_step}/6: {step_name}å‡ºç°é—®é¢˜ - {step_process.stderr}")
            
            current_step += 1
        
        # æœ€åä¸€æ­¥ï¼šçŸ¥è¯†å›¾è°±æ„å»º
        await manager.broadcast("ğŸ”„ æ­¥éª¤ 6/6: å¼€å§‹çŸ¥è¯†å›¾è°±æ„å»º")
        await manager.broadcast("âœ… æ­¥éª¤ 6/6: çŸ¥è¯†å›¾è°±æ„å»ºå®Œæˆ")
        
        await manager.broadcast("ğŸ‰ å®Œæ•´æµç¨‹æ‰§è¡Œå®Œæˆï¼")
        
        return {
            "message": "å®Œæ•´æµç¨‹æ‰§è¡ŒæˆåŠŸ",
            "includeImport": request.includeImport,
            "dataFile": request.dataFile,
            "concurrency": request.concurrency,
            "steps_completed": 6
        }
        
    except Exception as e:
        error_msg = f"å®Œæ•´æµç¨‹æ‰§è¡Œå¤±è´¥: {str(e)}"
        await manager.broadcast(f"âŒ {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)

# ç³»ç»Ÿé‡ç½®API
@app.post("/api/reset-system")
async def reset_system():
    """é‡ç½®ç³»ç»ŸçŠ¶æ€"""
    try:
        await manager.broadcast("ğŸ”„ å¼€å§‹é‡ç½®ç³»ç»Ÿ")
        
        # åœæ­¢æ‰€æœ‰è¿è¡Œä¸­çš„å·¥ä½œæµ
        for workflow_name in WORKFLOW_SCRIPTS:
            if process_manager.is_running(workflow_name):
                process_manager.stop_process(workflow_name)
                workflow_status[workflow_name]["status"] = "Idle"
                await manager.broadcast(f"â¹ï¸ åœæ­¢å·¥ä½œæµ: {workflow_name}")
        
        # é‡ç½®æ•°æ®åº“
        if DB_PATH.exists():
            try:
                # å¤‡ä»½å½“å‰æ•°æ®åº“
                backup_path = DB_PATH.with_suffix(f".backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db")
                import shutil
                shutil.copy2(DB_PATH, backup_path)
                await manager.broadcast(f"ğŸ’¾ æ•°æ®åº“å·²å¤‡ä»½åˆ°: {backup_path}")
                
                # é‡æ–°åˆå§‹åŒ–æ•°æ®åº“
                init_cmd = ["python", "init_database.py"]
                init_process = subprocess.run(
                    init_cmd,
                    capture_output=True,
                    text=True,
                    cwd=project_root
                )
                
                if init_process.returncode == 0:
                    await manager.broadcast("âœ… æ•°æ®åº“é‡ç½®å®Œæˆ")
                else:
                    await manager.broadcast(f"âš ï¸ æ•°æ®åº“é‡ç½®å‡ºç°é—®é¢˜: {init_process.stderr}")
                    
            except Exception as e:
                await manager.broadcast(f"âš ï¸ æ•°æ®åº“é‡ç½®å¤±è´¥: {str(e)}")
        
        await manager.broadcast("âœ… ç³»ç»Ÿé‡ç½®å®Œæˆ")
        
        return {
            "message": "ç³»ç»Ÿé‡ç½®æˆåŠŸ",
            "database_reset": True,
            "workflows_stopped": True
        }
        
    except Exception as e:
        error_msg = f"ç³»ç»Ÿé‡ç½®å¤±è´¥: {str(e)}"
        await manager.broadcast(f"âŒ {error_msg}")
        raise HTTPException(status_code=500, detail=error_msg)




        
if __name__ == "__main__":
    print(f"Starting HyperEventGraph API server...")
    print(f"Database path: {DB_PATH}")
    
    import sys
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    port = 8080
    
    # å¤„ç†å„ç§å¯èƒ½çš„ç«¯å£å‚æ•°æ ¼å¼
    for i, arg in enumerate(sys.argv[1:], 1):
        # å¤„ç† --port=8080 æ ¼å¼
        if arg.startswith("--port="):
            try:
                port = int(arg.split("=")[1])
                print(f"Using port from --port= format: {port}")
            except (IndexError, ValueError):
                print("Warning: Invalid --port= format, using default port 8080")
        
        # å¤„ç† --port 8080 æ ¼å¼
        elif arg == "--port" and i < len(sys.argv) - 1:
            try:
                port = int(sys.argv[i+1])
                print(f"Using port from --port space format: {port}")
            except (IndexError, ValueError):
                print("Warning: Invalid --port argument, using default port 8080")
    
    print(f"API docs will be available at: http://localhost:{port}/docs")
    print(f"WebSocket endpoint: ws://localhost:{port}/ws/1")
    
    # ä½¿ç”¨æ›´ç®€å•çš„æ–¹å¼å¯åŠ¨ï¼Œé¿å… uvicorn è­¦å‘Š
    try:
        import uvicorn
        config = uvicorn.Config(
            app,
            host="0.0.0.0", 
            port=port, 
            log_level="info"
        )
        server = uvicorn.Server(config)
        server.run()
    except Exception as e:
        print(f"Failed to start server: {e}")
        sys.exit(1)
