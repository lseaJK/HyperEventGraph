#!/usr/bin/env python3
"""
Enhanced FastAPI backend for HyperEventGraph web interface with improved logging.
"""

import sqlite3
import sys
import asyncio
import subprocess
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Optional
import json

from fastapi import FastAPI, HTTPException, WebSocket, WebSocketDisconnect, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
import uvicorn

app = FastAPI(
    title="HyperEventGraph API",
    description="Enhanced API for managing and visualizing the HyperEventGraph system.",
    version="0.2.0",
)

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173", "http://127.0.0.1:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configuration
project_root = Path(__file__).resolve().parent
DB_PATH = project_root / "master_state.db"

WORKFLOW_SCRIPTS = {
    "triage": "run_batch_triage.py",
    "extraction": "run_extraction_workflow.py", 
    "learning": "run_learning_workflow.py",
    "cortex": "run_cortex_workflow.py",
    "improved_cortex": "run_improved_cortex_workflow.py",
    "relationship_analysis": "run_relationship_analysis.py",
}

# Pydantic models
class WorkflowParams(BaseModel):
    clustering_threshold: float = None
    max_workers: int = None
    batch_size: int = None
    cluster_ratio: float = None
    
class FullPipelineRequest(BaseModel):
    includeImport: bool = False
    dataFile: str = ""
    clustering_threshold: float = None

# WebSocketè¿æ¥ç®¡ç†
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[int, WebSocket] = {}
        self.counter = 0

    async def connect(self, websocket: WebSocket) -> int:
        """æ¥å—WebSocketè¿æ¥"""
        await websocket.accept()
        self.counter += 1
        connection_id = self.counter
        self.active_connections[connection_id] = websocket
        return connection_id

    def disconnect(self, connection_id: int):
        """æ–­å¼€è¿æ¥"""
        if connection_id in self.active_connections:
            del self.active_connections[connection_id]

    async def send_personal_message(self, message: str, connection_id: int):
        """å‘é€ä¸ªäººæ¶ˆæ¯"""
        if connection_id in self.active_connections:
            websocket = self.active_connections[connection_id]
            try:
                await websocket.send_text(message)
            except:
                self.disconnect(connection_id)

    async def broadcast(self, message: str):
        """å¹¿æ’­æ¶ˆæ¯åˆ°æ‰€æœ‰è¿æ¥"""
        print(f"Broadcasting: {message}")  # æ§åˆ¶å°æ—¥å¿—
        disconnected = []
        for connection_id, websocket in self.active_connections.items():
            try:
                await websocket.send_text(message)
            except:
                disconnected.append(connection_id)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for connection_id in disconnected:
            self.disconnect(connection_id)

# å·¥ä½œæµè¿›ç¨‹ç®¡ç†
class WorkflowProcessManager:
    def __init__(self):
        self.running_processes: Dict[str, subprocess.Popen] = {}
        self.workflow_threads: Dict[str, threading.Thread] = {}
        self.stop_flags: Dict[str, bool] = {}
    
    def start_process(self, workflow_name: str, script_path: str, params: Dict = None) -> bool:
        """å¯åŠ¨å·¥ä½œæµè¿›ç¨‹"""
        if workflow_name in self.running_processes:
            return False
        
        try:
            cmd = ["python", script_path]
            if params:
                # å°†å‚æ•°è½¬æ¢ä¸ºå‘½ä»¤è¡Œå‚æ•°
                for key, value in params.items():
                    if value is not None:
                        cmd.extend([f"--{key}", str(value)])
            
            # å¯åŠ¨è¿›ç¨‹ï¼Œæ•è·è¾“å‡º
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,  # åˆå¹¶æ ‡å‡†é”™è¯¯åˆ°æ ‡å‡†è¾“å‡º
                text=True,
                bufsize=1,
                universal_newlines=True,
                cwd=project_root
            )
            
            self.running_processes[workflow_name] = process
            self.stop_flags[workflow_name] = False
            
            # åœ¨å•ç‹¬çº¿ç¨‹ä¸­ç›‘æ§è¿›ç¨‹è¾“å‡º
            thread = threading.Thread(
                target=self._monitor_process_sync,
                args=(workflow_name, process)
            )
            thread.daemon = True
            thread.start()
            
            self.workflow_threads[workflow_name] = thread
            return True
            
        except Exception as e:
            print(f"Failed to start workflow {workflow_name}: {e}")
            return False
    
    def _monitor_process_sync(self, workflow_name: str, process: subprocess.Popen):
        """åŒæ­¥ç›‘æ§è¿›ç¨‹è¾“å‡º"""
        def sync_broadcast(message: str):
            """åŒæ­¥ç‰ˆæœ¬çš„å¹¿æ’­"""
            try:
                # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯åœ¨çº¿ç¨‹ä¸­è¿è¡Œ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(manager.broadcast(message))
                loop.close()
            except Exception as e:
                print(f"Broadcast failed: {e}")
        
        try:
            sync_broadcast(f"ğŸš€ [{workflow_name}] å·¥ä½œæµå·²å¯åŠ¨")
            
            # é€è¡Œè¯»å–è¾“å‡º
            while True:
                if self.stop_flags.get(workflow_name, False):
                    break
                    
                output = process.stdout.readline()
                if output:
                    # è¿‡æ»¤æ‰ç©ºè¡Œå’Œæ— æ„ä¹‰çš„è¾“å‡º
                    line = output.strip()
                    if line and not line.startswith('WARNING'):
                        sync_broadcast(f"ğŸ“Š [{workflow_name}] {line}")
                
                # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦ç»“æŸ
                if process.poll() is not None:
                    break
                    
                time.sleep(0.1)
            
            # è¿›ç¨‹ç»“æŸåçš„çŠ¶æ€æ£€æŸ¥
            return_code = process.wait()
            if return_code == 0:
                sync_broadcast(f"âœ… [{workflow_name}] å·¥ä½œæµå®Œæˆ")
            else:
                sync_broadcast(f"âŒ [{workflow_name}] å·¥ä½œæµå¤±è´¥ (è¿”å›ç : {return_code})")
                
                # è¯»å–å‰©ä½™çš„é”™è¯¯è¾“å‡º
                remaining_output = process.stdout.read()
                if remaining_output:
                    sync_broadcast(f"âŒ [{workflow_name}] è¾“å‡ºè¯¦æƒ…: {remaining_output}")
            
        except Exception as e:
            sync_broadcast(f"âŒ [{workflow_name}] ç›‘æ§è¿›ç¨‹å¼‚å¸¸: {str(e)}")
        finally:
            # æ¸…ç†
            if workflow_name in self.running_processes:
                del self.running_processes[workflow_name]
            if workflow_name in self.workflow_threads:
                del self.workflow_threads[workflow_name]
            if workflow_name in self.stop_flags:
                del self.stop_flags[workflow_name]
    
    def stop_process(self, workflow_name: str) -> bool:
        """åœæ­¢å·¥ä½œæµè¿›ç¨‹"""
        if workflow_name not in self.running_processes:
            return False
        
        try:
            process = self.running_processes[workflow_name]
            self.stop_flags[workflow_name] = True
            
            # ä¼˜é›…åœæ­¢
            if process.poll() is None:
                process.terminate()
                
                # ç­‰å¾…5ç§’ï¼Œå¦‚æœè¿˜æ²¡åœæ­¢å°±å¼ºåˆ¶æ€æ­»
                try:
                    process.wait(timeout=5)
                except subprocess.TimeoutExpired:
                    process.kill()
                    process.wait()
            
            # æ¸…ç†
            if workflow_name in self.running_processes:
                del self.running_processes[workflow_name]
            if workflow_name in self.workflow_threads:
                del self.workflow_threads[workflow_name]
            if workflow_name in self.stop_flags:
                del self.stop_flags[workflow_name]
                
            return True
            
        except Exception as e:
            print(f"Failed to stop workflow {workflow_name}: {e}")
            return False
    
    def get_process_status(self, workflow_name: str) -> str:
        """è·å–è¿›ç¨‹çŠ¶æ€"""
        if workflow_name not in self.running_processes:
            return "Idle"
        
        process = self.running_processes[workflow_name]
        if process.poll() is None:
            return "Running"
        else:
            return "Completed"
    
    def is_running(self, workflow_name: str) -> bool:
        """æ£€æŸ¥å·¥ä½œæµæ˜¯å¦æ­£åœ¨è¿è¡Œ"""
        return (workflow_name in self.running_processes and 
                self.running_processes[workflow_name].poll() is None)

# å…¨å±€å®ä¾‹
manager = ConnectionManager()
process_manager = WorkflowProcessManager()
workflow_status = {name: {"status": "Idle", "last_run": None} for name in WORKFLOW_SCRIPTS}

# APIç«¯ç‚¹
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """WebSocketè¿æ¥ç«¯ç‚¹"""
    connection_id = await manager.connect(websocket)
    await manager.send_personal_message("ğŸ”— WebSocket connected", connection_id)
    
    try:
        while True:
            data = await websocket.receive_text()
            # å¯ä»¥åœ¨è¿™é‡Œå¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
            await manager.send_personal_message(f"Echo: {data}", connection_id)
    except WebSocketDisconnect:
        manager.disconnect(connection_id)

@app.get("/api/workflows")
async def get_workflows():
    """è·å–æ‰€æœ‰å·¥ä½œæµçŠ¶æ€"""
    workflows = []
    for name, script in WORKFLOW_SCRIPTS.items():
        status = process_manager.get_process_status(name)
        workflows.append({
            "name": name,
            "script": script,
            "status": status,
            "last_run": workflow_status[name]["last_run"]
        })
    return {"workflows": workflows}

@app.post("/api/workflows/{workflow_name}/start")
async def start_workflow(workflow_name: str, params: WorkflowParams = None, background_tasks: BackgroundTasks = None):
    """å¯åŠ¨ç‰¹å®šå·¥ä½œæµ"""
    if workflow_name not in WORKFLOW_SCRIPTS:
        raise HTTPException(status_code=404, detail=f"Workflow '{workflow_name}' not found")
    
    if process_manager.is_running(workflow_name):
        raise HTTPException(status_code=409, detail=f"Workflow '{workflow_name}' is already running")
    
    script_path = WORKFLOW_SCRIPTS[workflow_name]
    
    # è½¬æ¢å‚æ•°
    param_dict = {}
    if params:
        param_dict = params.dict(exclude_none=True)
    
    # å¯åŠ¨å·¥ä½œæµ
    success = process_manager.start_process(workflow_name, script_path, param_dict)
    
    if success:
        workflow_status[workflow_name]["status"] = "Running"
        workflow_status[workflow_name]["last_run"] = datetime.now().isoformat()
        await manager.broadcast(f"âœ… å·¥ä½œæµ '{workflow_name}' å·²å¯åŠ¨")
        return {"status": "started", "workflow": workflow_name}
    else:
        raise HTTPException(status_code=500, detail=f"Failed to start workflow '{workflow_name}'")

@app.post("/api/workflows/{workflow_name}/stop")
async def stop_workflow(workflow_name: str):
    """åœæ­¢ç‰¹å®šå·¥ä½œæµ"""
    if workflow_name not in WORKFLOW_SCRIPTS:
        raise HTTPException(status_code=404, detail=f"Workflow '{workflow_name}' not found")
    
    success = process_manager.stop_process(workflow_name)
    
    if success:
        workflow_status[workflow_name]["status"] = "Idle"
        await manager.broadcast(f"â¹ï¸ å·¥ä½œæµ '{workflow_name}' å·²åœæ­¢")
        return {"status": "stopped", "workflow": workflow_name}
    else:
        raise HTTPException(status_code=500, detail=f"Failed to stop workflow '{workflow_name}'")

@app.get("/api/events")
async def get_events():
    """è·å–äº‹ä»¶æ•°æ®"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT COUNT(*) FROM master_state")
            total_count = cursor.fetchone()[0]
            
            cursor.execute("SELECT current_status, COUNT(*) FROM master_state GROUP BY current_status")
            status_counts = dict(cursor.fetchall())
            
            cursor.execute("""
                SELECT id, source_text, current_status, assigned_event_type, 
                       triage_confidence, last_updated 
                FROM master_state 
                ORDER BY last_updated DESC 
                LIMIT 100
            """)
            recent_events = [
                {
                    "id": row[0],
                    "source_text": row[1][:200] + "..." if len(row[1]) > 200 else row[1],
                    "status": row[2],
                    "event_type": row[3],
                    "confidence": row[4],
                    "last_updated": row[5]
                }
                for row in cursor.fetchall()
            ]
            
            return {
                "total_count": total_count,
                "status_counts": status_counts,
                "recent_events": recent_events
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")

@app.get("/api/graph-data")
async def get_graph_data():
    """è·å–çŸ¥è¯†å›¾è°±æ•°æ®"""
    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            
            # è·å–äº‹ä»¶èŠ‚ç‚¹
            cursor.execute("""
                SELECT id, assigned_event_type, structured_data, involved_entities
                FROM master_state 
                WHERE current_status IN ('completed', 'pending_clustering', 'clustered')
                LIMIT 500
            """)
            
            nodes = []
            edges = []
            
            for row in cursor.fetchall():
                event_id, event_type, structured_data, entities_data = row
                
                # æ·»åŠ äº‹ä»¶èŠ‚ç‚¹
                nodes.append({
                    "id": event_id,
                    "label": event_type or "Unknown",
                    "type": "event",
                    "group": event_type or "unknown"
                })
                
                # è§£æå®ä½“æ•°æ®
                if entities_data:
                    try:
                        entities = json.loads(entities_data)
                        for entity in entities:
                            if isinstance(entity, dict):
                                entity_name = entity.get("entity_name", "")
                                entity_type = entity.get("entity_type", "Entity")
                                
                                if entity_name:
                                    # æ·»åŠ å®ä½“èŠ‚ç‚¹
                                    entity_id = f"entity_{entity_name}"
                                    if not any(n["id"] == entity_id for n in nodes):
                                        nodes.append({
                                            "id": entity_id,
                                            "label": entity_name,
                                            "type": "entity",
                                            "group": entity_type
                                        })
                                    
                                    # æ·»åŠ äº‹ä»¶-å®ä½“å…³ç³»
                                    edges.append({
                                        "source": event_id,
                                        "target": entity_id,
                                        "relationship": "INVOLVES"
                                    })
                    except (json.JSONDecodeError, TypeError):
                        pass
            
            return {
                "nodes": nodes[:200],  # é™åˆ¶èŠ‚ç‚¹æ•°é‡
                "edges": edges[:300]   # é™åˆ¶è¾¹æ•°é‡
            }
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Database error: {str(e)}")

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8080)
