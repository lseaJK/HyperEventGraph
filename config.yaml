# config.yaml
# This file centralizes all system configurations for the HyperEventGraph project.

# --- Database Configuration ---
database:
  path: "master_state.db"

# --- LLM Provider and Model Routing Configuration ---
# The system uses a unified LLM client that routes tasks to different models
# based on this configuration. API keys should be set as environment variables.
llm:
  providers:
    siliconflow:
      base_url: "https://api.siliconflow.cn/v1"
      # API key is read from the SILICON_API_KEY environment variable.

  models:
    # Model for initial triage: fast and cost-effective.
    triage:
      provider: "siliconflow"
      name: "deepseek-ai/DeepSeek-V3"
      temperature: 0.7
      top_p: 0.7
      max_tokens: 1024

    # Model for schema generation: powerful, large context.
    schema_generation:
      provider: "siliconflow"
      name: "deepseek-ai/DeepSeek-R1"
      temperature: 0.6
      top_p: 0.8

    # Model for extraction: strong instruction-following and JSON capabilities.
    extraction:
      provider: "siliconflow"
      name: "deepseek-ai/DeepSeek-R1"
      temperature: 0.3
      top_p: 0.8
      max_tokens: 10000

# --- Workflow Specific Configurations ---
review_workflow:
  # Path for the CSV file generated for human review.
  review_csv: "output/review/review_sheet.csv"

learning_workflow:
  # Path to the central JSON file where learned schemas are stored.
  schema_registry_path: "output/schemas/event_schemas.json"
  # Distance threshold for clustering similar texts. Lower is stricter.
  cluster_distance_threshold: 1.4

extraction_workflow:
  # Path for the final output file containing structured event data.
  output_file: "output/extraction/structured_events.jsonl"