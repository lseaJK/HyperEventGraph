#!/usr/bin/env python3
"""
ç®€å•çš„äº‹ä»¶å¯¼å…¥è„šæœ¬ï¼Œç›´æ¥å°†structured eventså¯¼å…¥æ•°æ®åº“
"""
import json
import hashlib
import sqlite3
from pathlib import Path

def import_events_simple(jsonl_file: str, db_path: str = "master_state.db"):
    """ç›´æ¥å¯¼å…¥äº‹ä»¶åˆ°æ•°æ®åº“"""
    print(f"ğŸš€ å¼€å§‹å¯¼å…¥äº‹ä»¶...")
    print(f"ğŸ“ æºæ–‡ä»¶: {jsonl_file}")
    print(f"ğŸ’¾ æ•°æ®åº“: {db_path}")
    
    # è¿æ¥æ•°æ®åº“
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # ç¡®ä¿è¡¨å­˜åœ¨
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS master_state (
            id TEXT PRIMARY KEY,
            source_text TEXT NOT NULL,
            current_status TEXT NOT NULL,
            triage_confidence REAL,
            assigned_event_type TEXT,
            story_id TEXT,
            notes TEXT,
            last_updated TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    imported = 0
    skipped = 0
    
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line_no, line in enumerate(f, 1):
            try:
                data = json.loads(line.strip())
                
                # è·å–åŸæ–‡
                source_text = data.get('text', '')
                if not source_text:
                    skipped += 1
                    continue
                
                # ç”ŸæˆID
                record_id = hashlib.md5(source_text.encode()).hexdigest()
                
                # æ’å…¥è®°å½•ï¼ˆå¦‚æœIDé‡å¤ä¼šè¢«å¿½ç•¥ï¼‰
                try:
                    cursor.execute("""
                        INSERT OR IGNORE INTO master_state 
                        (id, source_text, current_status, triage_confidence, assigned_event_type, notes)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (
                        record_id,
                        source_text,
                        'pending_clustering',
                        1.0,
                        data.get('event_type', 'unknown'),
                        f'Imported event: {data.get("description", "")[:100]}...'
                    ))
                    
                    if cursor.rowcount > 0:
                        imported += 1
                    else:
                        skipped += 1
                        
                except Exception as e:
                    print(f"âŒ ç¬¬{line_no}è¡Œæ’å…¥å¤±è´¥: {e}")
                    skipped += 1
                
                if line_no % 500 == 0:
                    print(f"ğŸ“Š å¤„ç†ä¸­... {line_no} è¡Œ")
                    conn.commit()
                    
            except Exception as e:
                print(f"âŒ ç¬¬{line_no}è¡Œå¤„ç†é”™è¯¯: {e}")
                skipped += 1
    
    conn.commit()
    
    # ç»Ÿè®¡ç»“æœ
    cursor.execute("SELECT COUNT(*) FROM master_state")
    total_records = cursor.fetchone()[0]
    
    cursor.execute("SELECT COUNT(*) FROM master_state WHERE current_status = 'pending_clustering'")
    clustering_records = cursor.fetchone()[0]
    
    conn.close()
    
    print(f"\nâœ… å¯¼å…¥å®Œæˆ!")
    print(f"ğŸ“Š æ–°å¯¼å…¥: {imported} æ¡")
    print(f"âš ï¸  è·³è¿‡: {skipped} æ¡")
    print(f"ğŸ“ˆ æ•°æ®åº“æ€»è®°å½•: {total_records} æ¡")
    print(f"ğŸ¯ å¾…èšç±»è®°å½•: {clustering_records} æ¡")
    
    return imported > 0

if __name__ == "__main__":
    import sys
    jsonl_file = sys.argv[1] if len(sys.argv) > 1 else "docs/output/structured_events_0730.jsonl"
    success = import_events_simple(jsonl_file)
    
    if success:
        print(f"\nğŸ¯ å»ºè®®ä¸‹ä¸€æ­¥:")
        print(f"1. æ£€æŸ¥çŠ¶æ€: python check_database_status.py")
        print(f"2. è¿è¡Œèšç±»: python run_cortex_workflow.py")
        print(f"3. å…³ç³»åˆ†æ: python run_relationship_analysis.py")
