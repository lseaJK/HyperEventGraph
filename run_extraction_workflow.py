# run_extraction_workflow.py
"""
This script runs the batch event extraction workflow.
It retrieves records marked as 'pending_extraction' from the database,
uses a powerful LLM with a fixed, detailed prompt to extract structured event data,
and saves the results to a JSONL file.
"""

import asyncio
import json
from pathlib import Path
import sys
import pandas as pd

# Add project root to sys.path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.core.config_loader import load_config, get_config
from src.core.database_manager import DatabaseManager
from src.llm.llm_client import LLMClient

def get_extraction_prompt(text_sample: str) -> str:
    """
    Generates the standardized extraction prompt.
    This function is a direct copy from the prompt tuning guide to ensure consistency.
    """
    return f"""
ä½ æ˜¯ä¸€åä¸“ä¸šçš„ä¿¡æ¯æŠ½å–ç³»ç»Ÿï¼Œä¸“æ³¨äºŽä»Žé›†æˆç”µè·¯ï¼ˆSemiconductorï¼‰å’Œç›¸å…³äº§ä¸šé¢†åŸŸçš„æ–°é—»ã€å…¬å‘Šã€ç ”ç©¶æŠ¥å‘Šä¸­è¯†åˆ«**å·²å‘ç”Ÿçš„æ˜Žç¡®ä¿¡æ¯æž„æˆçš„ç»“æž„åŒ–äº‹ä»¶**ã€‚

---

### ðŸŽ¯ ä»»åŠ¡ç›®æ ‡ï¼š

è¯·ä»Žè¾“å…¥æ–‡æœ¬ä¸­æŠ½å–**ä¸€ä¸ªæˆ–å¤šä¸ªå·²å‘ç”Ÿçš„äº‹å®žäº‹ä»¶**ï¼Œå¹¶æŒ‰å¦‚ä¸‹ JSON ç»“æž„è¾“å‡ºã€‚æ¯ä¸ªäº‹ä»¶ä½œä¸ºç‹¬ç«‹å¯¹è±¡ï¼Œç»Ÿä¸€è¿”å›žä¸º JSON æ•°ç»„ã€‚

---

### ðŸ§± æŠ½å–ç»´åº¦è¯´æ˜Žï¼š

æ¯ä¸ªäº‹ä»¶å¿…é¡»åŒ…æ‹¬ä»¥ä¸‹å­—æ®µï¼ˆæŸäº›ä¸ºå¯é€‰ï¼‰ï¼š

| å­—æ®µå | ç±»åž‹  | æè¿°  |
| --- | --- | --- |
| `event_type` | string | äº‹ä»¶ä¸»ç±»ï¼Œä¾‹å¦‚ï¼šMarketAction, SupplyChainDisruption, PolicyChange ç­‰ |
| `micro_event_type` | string | æ›´ç»†ç²’åº¦çš„äº‹ä»¶ç±»åž‹ï¼Œå¦‚ï¼šPriceReduction, CapacityChange, RevenueDrop ç­‰ |
| `event_date` | string or null | äº‹ä»¶å‘ç”Ÿæ—¶é—´ï¼Œå¦‚ `"2023-Q1"`ã€`"2023-H2"`ã€`"2025-07-30"`ï¼Œä¸æ˜Žç¡®åˆ™è®¾ä¸º `null` |
| `description` | string | ç”¨è‡ªç„¶è¯­è¨€ç®€è¦æè¿°è¯¥äº‹ä»¶ï¼ˆä¸è¦æ··å…¥é¢„æµ‹ï¼‰ |
| `involved_entities` | array | æ¶‰åŠçš„ä¼ä¸šã€æœºæž„ã€å›¢ä½“ |
| `quantitative_data` | object or null | è‹¥äº‹ä»¶ä¸­æåˆ°é‡åŒ–æŒ‡æ ‡ï¼ˆå¦‚ä»·æ ¼ã€æ”¶å…¥ã€åˆ©ç”¨çŽ‡ï¼‰åˆ™å¡«å†™ |
| `forecast` | null | **ä¸€å¾‹ä¸º nullï¼Œå› ä¸ºä¸æŠ½å–é¢„æµ‹ç±»äº‹ä»¶** |

---

### ðŸ“Œ event_type æŽ¨èå€¼ï¼š

- `"MarketAction"`ï¼šå¸‚åœºè¡Œä¸ºï¼Œå¦‚é™ä»·ã€æ¶¨ä»·ã€è¥æ”¶å˜åŠ¨
- `"SupplyChainDisruption"`ï¼šä¾›åº”é“¾å¹²æ‰°ï¼Œå¦‚åº“å­˜ã€äº§èƒ½é—®é¢˜
- `"PolicyChange"`ï¼šæ”¿ç­–å˜æ›´ï¼ˆå‡ºå£ç®¡åˆ¶ã€è¡¥è´´ç­‰ï¼‰
- `"ExecutiveChange"`ï¼šé«˜ç®¡å˜åŠ¨
- `"Partnership"`ï¼šå…¬å¸åˆä½œæˆ–å¹¶è´­
- `"LegalRegulation"`ï¼šæ³•å¾‹/åˆè§„ç›¸å…³åŠ¨ä½œ
- `"Other"`ï¼šå…¶ä»–æ˜Žç¡®å®šä¹‰çš„å·²å‘ç”Ÿäº‹ä»¶

---

### ðŸ“Œ ç‰¹åˆ«è¦æ±‚ï¼ˆæ ¸å¿ƒæŠ½å–é™åˆ¶ï¼‰ï¼š

> ðŸš« **ç»å¯¹ç¦æ­¢æŠ½å–é¢„æµ‹ç±»ã€è§‚ç‚¹ç±»ã€æŽ¨æµ‹ç±»å†…å®¹ä¸ºäº‹ä»¶ã€‚**
> - åŒ…å«â€œé¢„è®¡â€ã€â€œä¼°è®¡â€ã€â€œé¢„æµ‹â€ã€â€œæå°†â€ã€â€œå¯èƒ½â€ã€â€œæœ‰æœ›â€ç­‰è¡¨è¾¾çš„ä¿¡æ¯**ä¸€å¾‹å¿½ç•¥**ã€‚
> - åªä¿ç•™**å®¢è§‚ã€å·²å‘ç”Ÿçš„ã€æ˜Žç¡®ä¿¡æ¯æž„æˆçš„è¡Œä¸ºæˆ–ç»“æžœ**ã€‚
> - `forecast` å­—æ®µåœ¨æ‰€æœ‰äº‹ä»¶ä¸­å¿…é¡»è®¾ä¸º `null`ã€‚

---

### ðŸ“Œ è¾“å‡ºæ ¼å¼ï¼š

- è¿”å›žæ ¼å¼å¿…é¡»ä¸ºä¸€ä¸ª JSON æ•°ç»„ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªäº‹ä»¶å¯¹è±¡ã€‚
- æ¯ä¸ªäº‹ä»¶å¯¹è±¡å¿…é¡»éµå®ˆå¦‚ä¸‹ç»“æž„ï¼š
```json
{{ "event_type": "string", "micro_event_type": "string", "event_date": "string or null", "description": "string", "involved_entities": [ {{ "entity_name": "string", "entity_type": "Company | GovernmentAgency | IndustryGroup | ResearchAgency | IndustryExpert | Other", "role_in_event": "string or null" }} ], "quantitative_data": {{ "metric": "string or null", "value": "number or string", "unit": "string or null", "change_rate": "number or null", "period": "string or null" }} or null, "forecast": null }}
```

---

**Text to analyze:**
---
{text_sample}
---

**Your JSON Output:**
"""

async def run_extraction_workflow():
    """Main function to run the extraction workflow."""
    print("\n--- Running Event Extraction Workflow ---")
    config = get_config()
    db_path = config.get('database', {}).get('path')
    output_file_path = Path(config.get('extraction_workflow', {}).get('output_file'))
    
    if not db_path or not output_file_path:
        raise ValueError("Database path or output_file path not found in configuration.")

    output_file_path.parent.mkdir(exist_ok=True)
    
    db_manager = DatabaseManager(db_path)
    llm_client = LLMClient()

    print(f"Querying records with status 'pending_extraction' from '{db_path}'...")
    df_to_extract = db_manager.get_records_by_status_as_df('pending_extraction')

    if df_to_extract.empty:
        print("No items found with status 'pending_extraction'. Workflow complete.")
        return

    print(f"Found {len(df_to_extract)} records to process. Writing results to '{output_file_path}'...")

    with open(output_file_path, 'a', encoding='utf-8') as f:
        for index, row in df_to_extract.iterrows():
            record_id = row['id']
            text = row['source_text']
            
            print(f"\nProcessing record ID: {record_id}...")
            
            prompt = get_extraction_prompt(text)
            
            # We use get_raw_response because the new prompt expects an array, not a single object
            raw_response = await llm_client.get_raw_response(prompt, task_type="extraction")
            
            if not raw_response:
                print(f"  -> Failed to get response from LLM for record {record_id}.")
                db_manager.update_status_and_schema(record_id, "extraction_failed", "", "LLM call failed or returned empty.")
                continue

            try:
                extracted_events = json.loads(raw_response)
                if not isinstance(extracted_events, list):
                    raise json.JSONDecodeError("LLM did not return a JSON array.", raw_response, 0)

                print(f"  -> Successfully extracted {len(extracted_events)} event(s).")
                
                # Write each event as a new line in the JSONL file
                for event in extracted_events:
                    event['_source_id'] = record_id
                    event['_source_text'] = text
                    f.write(json.dumps(event, ensure_ascii=False) + '\n')
                
                db_manager.update_status_and_schema(record_id, "completed", "", f"Successfully extracted {len(extracted_events)} events.")

            except json.JSONDecodeError:
                print(f"  -> Failed to parse JSON array from LLM response for record {record_id}.")
                db_manager.update_status_and_schema(record_id, "extraction_failed", "", "LLM response was not a valid JSON array.")

    print("\n--- Event Extraction Workflow Finished ---")


def main():
    load_config("config.yaml")
    asyncio.run(run_extraction_workflow())

if __name__ == "__main__":
    main()
