# 技术文档 05: Cortex 上下文重建引擎

**关联章节**: [主架构文档第4章：核心技术与分析层](../HyperEventGraph_Architecture_V4.md#41-核心技术引擎)
**源目录**: `src/cortex/`

本篇文档深入剖析V4.0架构的核心创新——Cortex引擎。Cortex负责在海量、离散的事件之上重建有意义的上下文，将独立的“信息点”聚合成连贯的“故事线”，是实现高质量关系分析的先决条件。

---

## 1. 核心设计理念

Cortex的设计初衷是为了解决一个核心挑战：从不同时间、不同文档中抽取的事件本质上是孤立的，直接对它们进行关系分析，效果往往受限于局部信息。Cortex通过一个**“算法粗聚类 + LLM精炼”**的两阶段流程，智能地将描述同一个宏观事件的多个微观事件片段聚合在一起。

---

## 2. 核心组件与流程

Cortex引擎由 `run_cortex_workflow.py` 工作流驱动，其内部包含三个关键组件。

### 2.1. 向量化服务 (`vectorization_service.py`)

-   **职责**: 为Cortex的其他组件提供按需的、标准化的文本向量化能力。
-   **实现**:
    -   当前实现依赖 `sentence-transformers` 库，并使用 `config.yaml` 中���定的本地模型（如 `BAAI/bge-large-zh-v1.5`）来生成高质量的中文文本嵌入。
    -   设计上是可扩展的，未来可以轻松支持通过API调用其他向量化服务。

### 2.2. 聚类协调器 (`clustering_orchestrator.py`)

这是执行“算法粗聚类”的核心，负责从数千个离散事件中发现潜在的关联性。

-   **核心算法**: **带权重的混合距离 DBSCAN**。
    -   **DBSCAN**: 选择DBSCAN是因为它不需要预先指定簇的数量，并且能很好地识别和处理噪声点（即无法归入任何簇的孤立事件），这非常适合我们处理复杂、真实世界数据的场景。
    -   **混合距离度量**: 这是该组件的关键创新。它不单纯依赖语义相似度，而是将两种“相似度”加权融合，以获得更精准的聚类效果：
        1.  **语义距离 (Cosine Distance)**: 通过 `vectorization_service` 获得所有事件描述的向量，然后计算它们之间的余弦距离矩阵。这捕捉了事件在**内容描述**上的相似性。
        2.  **实体距离 (Jaccard Distance)**: 计算每对事件之间**共现实体**的Jaccard距离。如果两个事件都提到了“A公司”和“B芯片”，即使它们的文本描述差异较大，它们的实体距离也会很近。这捕捉了事件在**核心参与者**上的关联性。
        3.  **加权融合**: 最终的距离矩阵由以下公式生成：
            `Combined_Dist = (1 - entity_weight) * Cosine_Dist + entity_weight * Jaccard_Dist`
            其中 `entity_weight` 是一个在 `config.yaml` 中可调的超参数，允许我们根据数据特性调整两种相似度的重要性。

-   **输出**:
    -   该组件的输出是一个从 `event_id` 到 `cluster_id` 的映射。这个映射会被写回 `master_state.db`，同时状态被更新为 `pending_refinement`。

### 2.3. 精炼代理 (`refinement_agent.py`)

这是执行“LLM精炼”的核心，负责将算法生成的、可能还很粗糙的“簇”提炼成逻辑清晰、可供下游分析的“故事单元”。

-   **职责**:
    -   为每个簇生成一个唯一的 `story_id`。
    -   为每个故事生成一个高质量的、概括性的**摘要**。
    -   处理超大簇，确保LLM在上下文窗口和注意力方面的局限性不会影响最终质量。

-   **核心逻辑**:
    -   **小簇处理**: 如果一个簇的事件数量低于 `config.yaml` 中定义的 `large_cluster_threshold` 阈值，Agent会将簇内所有事件的描述拼接起来，调用LLM一次性生成最终的故事摘要。
    -   **大簇处理 (分块-摘要-合并策略)**: 这是处理大规模相关事件的关键。
        1.  **分块 (Chunking)**: 将大簇中的事件列表分割成多个大小适中（由`chunk_size`定义）的小块。
        2.  **并行摘要 (Summarize in Parallel)**: **并发地**为每一个小块调用LLM，生成各自的初步摘要。这极大地提升了处理速度。
        3.  **合并 (Merge)**: 将所有初步摘要拼接起来，然后再次调用LLM，并赋予其“总编辑”的角色，要求它将这些摘要融合成一个单一的、连贯的、去重后的最终故事摘要。

-   **输出**:
    -   该组件的输出是一个或多个“故事”对象，每个对象包含 `story_id`、`summary` 和所包含的 `event_ids` 列表。这些信息将被写回 `master_state.db`，并且事件状态被更新为 `pending_relationship_analysis`，正式移交给下一个工作流。

---

## 3. 核心模块辨析：Cortex vs. 模式学习 (Schema Learning)

为了避免混淆，必须清晰地定义Cortex引擎和模式学习这两个都使用了“聚类”技术的模块之间的根本区别。它们服务于知识循环中完全不同且互补的两个环节，并不冗余，也不能合并。

| 特性 | **Cortex (故事发现)** | **模式学习 (Schema Learning)** |
| :--- | :--- | :--- |
| **核心目标** | **重建上下文 (Context Reconstruction)** | **定义概念 (Concept Definition)** |
| **解决的问题** | “这里有50个独立的事件，都和A公司的芯片生产有关。**它们是不是在讲述同一个故事？**” | “我们遇到了很多描述‘高管变动’的事件，但我们还没有一个正式的‘高管变动’模板。**我们来定义一个吧！**” |
| **输入数据** | 所有状态为 **`pending_clustering`** 的**已知原子事件**。 | 由人类专家标记为 **`pending_learning`** 的**未知事件**。 |
| **核心方法** | **全自动聚类** + **LLM精炼**。 | **交互式聚类** + **人机协同**。 |
| **输出结果** | 一个 **`story_id`**，将一组原子事件关联在一起，并生成一段**故事摘要**。 | 一个新的或更新的 **事件Schema**（规则），写入 `event_schemas.json`。 |
| **工作流位置** | **数据处理阶段**（在事件抽取之后，关系分析之前）。 | **知识获取阶段**（在主流水线之前，负责为系统“备课”）。 |

**总结：** Cortex是“将已知组织化”，负责在已知的知识点中发现更高维度的叙事结构。而模式学习是“从未知到已知”，负责扩大系统的认知边界。我们必须先通过模式学习学会一个“概念”，才能在后续通过Cortex发现关于这个概念的“故事”。
