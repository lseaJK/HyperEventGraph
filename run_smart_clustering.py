#!/usr/bin/env python3
"""
ä¸“é—¨é’ˆå¯¹ç§‘åˆ›æ¿æ•°æ®çš„æ™ºèƒ½èšç±»ç³»ç»Ÿ
åŸºäºæŠ•èµ„åˆ†æéœ€æ±‚è®¾è®¡çš„å¤šç»´åº¦èšç±»ç­–ç•¥
"""

import os
import requests
import json
import uuid
import argparse
import re
from pathlib import Path
import sys
from typing import List, Dict, Set
from collections import defaultdict
from datetime import datetime, timedelta

# Add project root to sys.path
project_root = Path(__file__).resolve().parent
sys.path.insert(0, str(project_root))

from src.core.config_loader import load_config, get_config
from src.core.database_manager import DatabaseManager

def direct_llm_call(prompt, model="deepseek-ai/DeepSeek-V2.5"):
    """ç›´æ¥è°ƒç”¨APIï¼Œç»•è¿‡é¡¹ç›®çš„LLMClient"""
    api_key = os.getenv('SILICONFLOW_API_KEY')
    if not api_key:
        raise ValueError("éœ€è¦SILICONFLOW_API_KEYç¯å¢ƒå˜é‡")
    
    url = "https://api.siliconflow.cn/v1/chat/completions"
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    data = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 1000,
        "temperature": 0.3  # é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ä¸€è‡´çš„ç»“æœ
    }
    
    response = requests.post(url, headers=headers, json=data, timeout=30)
    
    if response.status_code == 200:
        result = response.json()
        return result['choices'][0]['message']['content']
    else:
        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")

class CompanyExtractor:
    """å…¬å¸åç§°æå–å™¨"""
    
    def __init__(self):
        # å¸¸è§çš„å…¬å¸åç¼€
        self.company_suffixes = [
            'å…¬å¸', 'é›†å›¢', 'è‚¡ä»½', 'æœ‰é™å…¬å¸', 'ç§‘æŠ€', 'ç”µå­', 'åŠå¯¼ä½“', 'å¾®ç”µå­',
            'å®ä¸š', 'æ§è‚¡', 'æŠ•èµ„', 'å‘å±•', 'å›½é™…', 'æŠ€æœ¯', 'å·¥ä¸š', 'åˆ¶é€ ',
            'Corp', 'Inc', 'Ltd', 'Technology', 'Electronics', 'Semiconductor'
        ]
        
        # æ’é™¤çš„é€šç”¨è¯
        self.exclude_words = {'ä¸­å›½', 'å…¨çƒ', 'å›½å†…', 'æµ·å¤–', 'å¸‚åœº', 'è¡Œä¸š', 'äº§ä¸š'}
    
    def extract_companies(self, text: str) -> Set[str]:
        """ä»æ–‡æœ¬ä¸­æå–å…¬å¸åç§°"""
        companies = set()
        
        # æ–¹æ³•1ï¼šæ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
        # åŒ¹é…ä¸­æ–‡å…¬å¸åï¼ˆ2-10ä¸ªæ±‰å­— + å…¬å¸åç¼€ï¼‰
        pattern_cn = r'([ä¸€-é¾¥]{2,10}(?:' + '|'.join(self.company_suffixes[:12]) + '))'
        matches_cn = re.findall(pattern_cn, text)
        companies.update(matches_cn)
        
        # æ–¹æ³•2ï¼šåŒ¹é…è‹±æ–‡å…¬å¸å
        pattern_en = r'([A-Z][A-Za-z\s]{2,20}(?:' + '|'.join(self.company_suffixes[12:]) + '))'
        matches_en = re.findall(pattern_en, text)
        companies.update(matches_en)
        
        # æ–¹æ³•3ï¼šåŒ¹é…è‚¡ç¥¨ä»£ç ç›¸å…³çš„å…¬å¸å
        pattern_stock = r'([ä¸€-é¾¥A-Za-z]{2,10})[ï¼ˆ(][\d]{6}[ï¼‰)]'
        matches_stock = re.findall(pattern_stock, text)
        companies.update(matches_stock)
        
        # è¿‡æ»¤ç»“æœ
        filtered_companies = set()
        for company in companies:
            if (len(company) >= 2 and 
                company not in self.exclude_words and
                not company.isdigit()):
                filtered_companies.add(company)
        
        return filtered_companies

class ThemeExtractor:
    """ä¸»é¢˜æå–å™¨"""
    
    def __init__(self):
        # ç§‘åˆ›æ¿ç›¸å…³çš„å…³é”®ä¸»é¢˜
        self.themes = {
            'èŠ¯ç‰‡çŸ­ç¼º': ['èŠ¯ç‰‡çŸ­ç¼º', 'ç¼ºèŠ¯', 'èŠ¯ç‰‡ä¾›åº”', 'èŠ¯ç‰‡ç´§å¼ ', 'åŠå¯¼ä½“çŸ­ç¼º'],
            'äº§èƒ½æ‰©å¼ ': ['æ‰©äº§', 'äº§èƒ½', 'æ–°å»ºäº§çº¿', 'æŠ•äº§', 'é‡äº§', 'å¼€å·¥å»ºè®¾'],
            'ä»·æ ¼æ³¢åŠ¨': ['æ¶¨ä»·', 'é™ä»·', 'ä»·æ ¼ä¸Šæ¶¨', 'ä»·æ ¼ä¸‹è·Œ', 'ä»·æ ¼æ³¢åŠ¨', 'æˆæœ¬ä¸Šå‡'],
            'ä¸šç»©å‘å¸ƒ': ['å‡€åˆ©æ¶¦', 'è¥æ”¶', 'è´¢æŠ¥', 'ä¸šç»©', 'å¹´æŠ¥', 'å­£æŠ¥', 'åŠå¹´æŠ¥'],
            'æŠ€æœ¯çªç ´': ['çªç ´', 'åˆ›æ–°', 'ç ”å‘', 'æŠ€æœ¯', 'ä¸“åˆ©', 'å·¥è‰º', 'åˆ¶ç¨‹'],
            'åˆä½œå¹¶è´­': ['åˆä½œ', 'å¹¶è´­', 'æ”¶è´­', 'æŠ•èµ„', 'æˆ˜ç•¥åˆä½œ', 'åˆèµ„'],
            'æ”¿ç­–å½±å“': ['æ”¿ç­–', 'ç›‘ç®¡', 'æ”¿åºœ', 'è¡¥è´´', 'ç¨æ”¶', 'æ³•è§„'],
            'ä¾›åº”é“¾': ['ä¾›åº”é“¾', 'ä¸Šæ¸¸', 'ä¸‹æ¸¸', 'ä¾›åº”å•†', 'å®¢æˆ·', 'è®¢å•'],
            'æ–°äº§å“å‘å¸ƒ': ['å‘å¸ƒ', 'æ¨å‡º', 'ä¸Šå¸‚', 'æ–°å“', 'äº§å“', 'è§£å†³æ–¹æ¡ˆ'],
            'å¸‚åœºå˜åŒ–': ['å¸‚åœº', 'éœ€æ±‚', 'é”€å”®', 'å‡ºè´§', 'åº“å­˜', 'æ¸ é“']
        }
    
    def extract_themes(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–ä¸»é¢˜"""
        found_themes = []
        text_lower = text.lower()
        
        for theme, keywords in self.themes.items():
            if any(keyword in text for keyword in keywords):
                found_themes.append(theme)
        
        return found_themes

class SmartClustering:
    """æ™ºèƒ½èšç±»ç³»ç»Ÿ"""
    
    def __init__(self, clustering_mode='company'):
        self.company_extractor = CompanyExtractor()
        self.theme_extractor = ThemeExtractor()
        self.clustering_mode = clustering_mode
    
    def company_based_clustering(self, events: List[Dict]) -> Dict[str, List[Dict]]:
        """åŸºäºå…¬å¸çš„èšç±»"""
        print("ğŸ¢ æ‰§è¡ŒåŸºäºå…¬å¸çš„èšç±»...")
        
        company_groups = defaultdict(list)
        
        for event in events:
            text = event.get('source_text', '')
            companies = self.company_extractor.extract_companies(text)
            
            if companies:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¯†åˆ«çš„å…¬å¸ä½œä¸ºä¸»è¦å…¬å¸
                main_company = list(companies)[0]
                company_groups[main_company].append(event)
            else:
                # æœªè¯†åˆ«åˆ°å…¬å¸çš„äº‹ä»¶æ”¾å…¥é€šç”¨ç»„
                company_groups['å…¶ä»–å…¬å¸'].append(event)
        
        print(f"ğŸ“Š è¯†åˆ«åˆ° {len(company_groups)} ä¸ªå…¬å¸åˆ†ç»„")
        for company, events in list(company_groups.items())[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
            print(f"  - {company}: {len(events)} ä¸ªäº‹ä»¶")
        
        return dict(company_groups)
    
    def theme_based_clustering(self, events: List[Dict]) -> Dict[str, List[Dict]]:
        """åŸºäºä¸»é¢˜çš„èšç±»"""
        print("ğŸ¯ æ‰§è¡ŒåŸºäºä¸»é¢˜çš„èšç±»...")
        
        theme_groups = defaultdict(list)
        
        for event in events:
            text = event.get('source_text', '')
            themes = self.theme_extractor.extract_themes(text)
            
            if themes:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªè¯†åˆ«çš„ä¸»é¢˜ä½œä¸ºä¸»è¦ä¸»é¢˜
                main_theme = themes[0]
                theme_groups[main_theme].append(event)
            else:
                # æœªè¯†åˆ«åˆ°ä¸»é¢˜çš„äº‹ä»¶æ ¹æ®äº‹ä»¶ç±»å‹åˆ†ç»„
                event_type = event.get('assigned_event_type', 'å…¶ä»–')
                theme_groups[f"å…¶ä»–_{event_type}"].append(event)
        
        print(f"ğŸ“Š è¯†åˆ«åˆ° {len(theme_groups)} ä¸ªä¸»é¢˜åˆ†ç»„")
        for theme, events in theme_groups.items():
            print(f"  - {theme}: {len(events)} ä¸ªäº‹ä»¶")
        
        return dict(theme_groups)
    
    def hybrid_clustering(self, events: List[Dict]) -> Dict[str, List[Dict]]:
        """æ··åˆèšç±»ï¼šå…¬å¸+ä¸»é¢˜"""
        print("ğŸ”„ æ‰§è¡Œæ··åˆèšç±»ï¼ˆå…¬å¸+ä¸»é¢˜ï¼‰...")
        
        hybrid_groups = defaultdict(list)
        
        for event in events:
            text = event.get('source_text', '')
            companies = self.company_extractor.extract_companies(text)
            themes = self.theme_extractor.extract_themes(text)
            
            # æ„å»ºå¤åˆé”®
            if companies and themes:
                company = list(companies)[0]
                theme = themes[0]
                key = f"{company}_{theme}"
            elif companies:
                company = list(companies)[0]
                key = f"{company}_ç»¼åˆäº‹ä»¶"
            elif themes:
                theme = themes[0]
                key = f"è¡Œä¸š_{theme}"
            else:
                event_type = event.get('assigned_event_type', 'å…¶ä»–')
                key = f"å…¶ä»–_{event_type}"
            
            hybrid_groups[key].append(event)
        
        print(f"ğŸ“Š è¯†åˆ«åˆ° {len(hybrid_groups)} ä¸ªæ··åˆåˆ†ç»„")
        for key, events in list(hybrid_groups.items())[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
            print(f"  - {key}: {len(events)} ä¸ªäº‹ä»¶")
        
        return dict(hybrid_groups)
    
    def cluster_events(self, events: List[Dict]) -> Dict[str, List[Dict]]:
        """æ ¹æ®æ¨¡å¼æ‰§è¡Œèšç±»"""
        if self.clustering_mode == 'company':
            return self.company_based_clustering(events)
        elif self.clustering_mode == 'theme':
            return self.theme_based_clustering(events)
        elif self.clustering_mode == 'hybrid':
            return self.hybrid_clustering(events)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„èšç±»æ¨¡å¼: {self.clustering_mode}")

def process_cluster_with_refinement(group_name: str, events: List[Dict], max_story_size: int = 20) -> List[Dict]:
    """å¤„ç†å•ä¸ªèšç±»ç»„ï¼Œå¦‚æœäº‹ä»¶è¿‡å¤šåˆ™è¿›ä¸€æ­¥ç»†åˆ†"""
    stories = []
    
    if len(events) <= max_story_size:
        # äº‹ä»¶æ•°é‡é€‚ä¸­ï¼Œç›´æ¥åˆ›å»ºä¸€ä¸ªæ•…äº‹
        story = create_story_from_events(group_name, events)
        stories.append(story)
    else:
        # äº‹ä»¶è¿‡å¤šï¼Œéœ€è¦è¿›ä¸€æ­¥ç»†åˆ†
        print(f"  ğŸ“¦ {group_name} äº‹ä»¶è¿‡å¤š({len(events)})ï¼Œè¿›è¡Œç»†åˆ†...")
        
        # æŒ‰æ—¶é—´æ’åº
        sorted_events = sorted(events, key=lambda x: x.get('last_updated', ''), reverse=True)
        
        # åˆ†æ‰¹å¤„ç†
        for i in range(0, len(sorted_events), max_story_size):
            batch_events = sorted_events[i:i+max_story_size]
            batch_name = f"{group_name}_æ‰¹æ¬¡{i//max_story_size + 1}"
            story = create_story_from_events(batch_name, batch_events)
            stories.append(story)
    
    return stories

def create_story_from_events(group_name: str, events: List[Dict]) -> Dict:
    """ä»äº‹ä»¶åˆ—è¡¨åˆ›å»ºæ•…äº‹"""
    try:
        story_id = f"story_{uuid.uuid4().hex[:8]}"
        
        # ç”Ÿæˆæ™ºèƒ½æ‘˜è¦
        if len(events) <= 3:
            # äº‹ä»¶è¾ƒå°‘ï¼Œç›´æ¥æ‹¼æ¥
            texts = [event['source_text'][:100] for event in events]
            summary = " | ".join(texts)
        else:
            # äº‹ä»¶è¾ƒå¤šï¼Œä½¿ç”¨LLMç”Ÿæˆæ‘˜è¦
            texts = [f"{i+1}. {event['source_text'][:150]}" for i, event in enumerate(events[:5])]
            combined_text = "\n".join(texts)
            
            prompt = f"""
è¯·ä¸ºä»¥ä¸‹å…³äº"{group_name}"çš„{len(events)}ä¸ªç›¸å…³äº‹ä»¶ç”Ÿæˆä¸€ä¸ªç®€æ´çš„æŠ•èµ„åˆ†ææ‘˜è¦ï¼ˆ2-3å¥è¯ï¼‰ï¼š

{combined_text}

æ‘˜è¦åº”è¯¥ï¼š
1. çªå‡ºå…³é”®çš„æŠ•èµ„ä¿¡æ¯å’Œå¸‚åœºå½±å“
2. è¯†åˆ«ä¸»è¦çš„é£é™©æˆ–æœºä¼š
3. ä¿æŒå®¢è§‚å’Œä¸“ä¸šçš„è¯­è°ƒ

è¯·ç›´æ¥å›å¤æ‘˜è¦å†…å®¹ï¼š
"""
            
            try:
                summary = direct_llm_call(prompt)
            except:
                summary = f"{group_name}ç›¸å…³çš„{len(events)}ä¸ªäº‹ä»¶"
        
        return {
            'story_id': story_id,
            'event_ids': [event['id'] for event in events],
            'summary': summary[:300],  # é™åˆ¶æ‘˜è¦é•¿åº¦
            'group_name': group_name,
            'event_count': len(events)
        }
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºæ•…äº‹å¤±è´¥: {e}")
        return None

def run_smart_clustering_workflow(clustering_mode='company', max_story_size=20):
    """æ™ºèƒ½èšç±»å·¥ä½œæµä¸»å‡½æ•°"""
    print(f"\n--- Running Smart Clustering Workflow ---")
    print(f"ğŸ¯ èšç±»æ¨¡å¼: {clustering_mode}")
    print(f"ğŸ“Š æœ€å¤§æ•…äº‹å¤§å°: {max_story_size}")
    
    # 0. Load configuration
    config_path = project_root / "config.yaml"
    load_config(config_path)
    print("âœ… Configuration loaded successfully")
    
    # 1. Initialization
    config = get_config()
    db_path = config.get('database', {}).get('path')
    db_manager = DatabaseManager(db_path)

    # 2. Fetch pending events
    print("Fetching events pending clustering from the database...")
    events_to_cluster = db_manager.get_records_by_status_as_df('pending_clustering').to_dict('records')
    
    if not events_to_cluster:
        print("No events found pending clustering. Workflow complete.")
        return

    print(f"Found {len(events_to_cluster)} events to process.")

    # 3. æ‰§è¡Œæ™ºèƒ½èšç±»
    clusterer = SmartClustering(clustering_mode)
    cluster_groups = clusterer.cluster_events(events_to_cluster)
    
    # 4. å¤„ç†æ¯ä¸ªèšç±»ç»„
    all_stories = []
    processed_events = 0
    
    print(f"\nğŸ”„ å¤„ç† {len(cluster_groups)} ä¸ªèšç±»ç»„...")
    
    for group_name, group_events in cluster_groups.items():
        print(f"\nğŸ“ å¤„ç†åˆ†ç»„: {group_name} ({len(group_events)} ä¸ªäº‹ä»¶)")
        
        # å¤„ç†å•ä¸ªèšç±»ç»„
        stories = process_cluster_with_refinement(group_name, group_events, max_story_size)
        
        for story in stories:
            if story:
                all_stories.append(story)
                processed_events += story['event_count']
                print(f"  âœ… æ•…äº‹ {story['story_id']}: {story['event_count']} ä¸ªäº‹ä»¶")
                print(f"     æ‘˜è¦: {story['summary'][:80]}...")

    # 5. Update database with story information
    if not all_stories:
        print("\nNo stories were generated. No database updates to perform.")
    else:
        print(f"\nğŸ“Š èšç±»ç»Ÿè®¡:")
        print(f"  æ€»äº‹ä»¶æ•°: {len(events_to_cluster)}")
        print(f"  æˆåŠŸå¤„ç†: {processed_events}")
        print(f"  ç”Ÿæˆæ•…äº‹: {len(all_stories)}")
        print(f"  å¹³å‡æ¯æ•…äº‹äº‹ä»¶æ•°: {processed_events / len(all_stories):.1f}")
        
        print("\nUpdating database...")
        successful_updates = 0
        
        for i, story in enumerate(all_stories):
            story_id = story['story_id']
            event_ids_in_story = story['event_ids']
            
            try:
                db_manager.update_story_info(event_ids_in_story, story_id, 'pending_relationship_analysis')
                successful_updates += 1
                
                if i % 20 == 0:  # æ¯20ä¸ªæ•…äº‹æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                    print(f"  âœ… å·²æ›´æ–° {i+1}/{len(all_stories)} ä¸ªæ•…äº‹")
                    
            except Exception as e:
                print(f"  âŒ æ•…äº‹ {story_id} æ›´æ–°å¤±è´¥: {e}")
        
        print(f"\nâœ… Database updateå®Œæˆ: {successful_updates}/{len(all_stories)} æ•…äº‹æˆåŠŸæ›´æ–°")

    print("\n--- Smart Clustering Workflow Finished ---")

def main():
    """Entry point with argument parsing."""
    parser = argparse.ArgumentParser(description="ç§‘åˆ›æ¿æ™ºèƒ½èšç±»å·¥ä½œæµ")
    parser.add_argument("--mode", choices=['company', 'theme', 'hybrid'], default='company',
                       help="èšç±»æ¨¡å¼ (é»˜è®¤: company)")
    parser.add_argument("--max_story_size", type=int, default=20,
                       help="å•ä¸ªæ•…äº‹çš„æœ€å¤§äº‹ä»¶æ•° (é»˜è®¤: 20)")
    
    args = parser.parse_args()
    
    print("Initializing smart clustering workflow...")
    try:
        run_smart_clustering_workflow(args.mode, args.max_story_size)
        print("ğŸ‰ æ™ºèƒ½èšç±»å·¥ä½œæµå®Œæˆ!")
    except Exception as e:
        print(f"âŒ å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
